{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJztnXfcHUW9/z+ze8pT0pMnJCQkTxICoYQaQgKRIiBNRbFgrHgpFxWv7aLhYr8qXOUq1ys/rijYRRFp0qIUpUhLIISEVCAJ6b0+7Zzd+f2xO7uzszN7ds/Z57Rn3q9XXnnOOXv2zO7OfOc73/kWQimFRqPRaAYWRq0boNFoNJrqo4W/RqPRDEC08NdoNJoBiBb+Go1GMwDRwl+j0WgGIFr4azQazQBEC3+NRqMZgGjhr9FoNAMQLfw1Go1mAJKpdQNUjBo1inZ2dta6GRqNRtNQLFy4cDultKPUcXUr/Ds7O7FgwYJaN0Oj0WgaCkLI2jjHabOPRqPRDEC08NdoNJoBiBb+Go1GMwDRwl+j0WgGIFr4azQazQBEC3+NRqMZgGjhr9FoNAMQLfyblHU7uvDkym21boZGo6lT6jbIS1MZp9/4BCgF1txwYa2botFo6pBUNH9CyO2EkK2EkCWKz88ghOwhhCxy/309jd/VqKG01i3QaDT1TFqa/y8B/ATAryOOeYpS+s6Ufk+j0Wg0FZCK5k8pfRLAzjTOpdFoNJr+p5obvrMJIa8QQh4mhBwlO4AQciUhZAEhZMG2bXqzMg0sW9t/NBpNmGoJ/5cATKSUHgvgfwHcKzuIUnorpXQGpXRGR0fJjKSaGBQsu9ZN0Gg0dUhVhD+ldC+ldL/790MAsoSQUdX47YGOFv4ajUZGVYQ/IWQMIYS4f890f3dHNX57oFOwtNlHo9GEScXbhxByB4AzAIwihKwH8A0AWQCglP4fgPcD+BQhpAigG8CHKNXOiNWgqDV/jUYjIRXhTymdW+Lzn8BxBdVUmT4t/DUajQSd3qHJKWqzj0ajkaCFf5NTtLXmr9Fowmjh3+T0FbXmr9Fowmjh36Q4vlVa89doNHK08G9STFf6az9/jUYjQwv/JoVp/lr2azQaGVr4Nzk6t49Go5GhhX+To2PpNBqNDC38mxQCx+5jaeGv0WgkaOHfrHg2fy38NRpNGC38mxRX9sPWmr9Go5GghX+To938NRqNDC38mxxt89doNDK08G9SmJ+/rW3+Go1Gghb+TYr29tFoNFFo4a+gu8/Cgd5irZtRMdrbR6PRyNDCX8Gs6x/DUd+YX+tmVIxW/DUajQwt/BXs6S7UugkVQbSfv0ajiUAL/yaF+flrm79Go5GhhX+TQlzVX3v7aDQaGVr4Nzla9ms0Ghla+Jeg2KAJ8fe7nkra7KPRaGRo4V+CroJV6yYk5qV1u7y/tdlHo9HI0MK/BD19jSf8dx3o8/7W3j4ajUaGFv4laESzyZDWrPe3zuqp0WhkaOFfgqLVeMKT1/abSfi/tG4XOuc9iMXrd9e6KRpNw5OK8CeE3E4I2UoIWaL4nBBCfkwIWU0IWUwIOSGN360GjWg24SesBt2vlvL3FdsAAB/52fM1bolG0/ikpfn/EsB5EZ+fD2Cq++9KALek9Lv9TrERhT+XxL+ZNP98xumu+5og55JGU2tSEf6U0icB7Iw45CIAv6YOzwEYRggZm8Zv9zeNr/k3XvtVMOGv0Wgqp1qjaRyAt7jX6933AhBCriSELCCELNi2bVuVmhZNsQFLYRWb1Oafz5q1boJmgNNTaI5sv0D1hD+RvBeSSpTSWymlMyilMzo6OqrQrNI0ouYcMPs0YPtVaM1fU2tmN0m2X6B6wn89gEO41+MBbKzSb1dEQ9r8ebNPHWv+v31uLTrnPYiemIF0vPCndXxdmuZlV1djZ/vlqZbwvx/Ax12vn1kA9lBKN1XptyuiMTX/xvD2uenRVQCAvTHTZ2dNv7sWGtAFVyPn0de24DfPrql1MwYcmTROQgi5A8AZAEYRQtYD+AaALABQSv8PwEMALgCwGkAXgE+m8bvVoBH9/Pl8RPVt83fbJjMKyo7mLqW3aCGnzUBNweW/XgAA+Njszto2ZICRivCnlM4t8TkF8Jk0fqvaNLrmX8+TF/Vkfzzpz09kvUUbg/ujURrNAEGrTiUo1LPdRAGv+Vt17K1Evf8pdnf1oXPeg5HLf1H4azSa8tHCvwSf/OWLeGzZllo3IxFM88+ZRl1vWLNNW9sGdrjJ6G57+k3l8bzwj7tJrNFo5GjhH4NHl22tdRMSwQR+PmPUtdmKtcyiFDl3M3dfj9qHml/ENIuvtUZTK1Kx+Tc7OTPmjmSdwMw++axZ18KfUeBMOFGpG3jNP2qS0Gg0pdHCPwa8i2Ej0DCav9u0M278O95/4ngAQF+ELZ/39tnX0zz+1v3FbU+/iZ0HenHNudNq3RRNHdJYUq1GZBvMpbBoURgEyGUaw+YPAHctXF/yeEtr/on4zwdew81PvF7rZmjqlMaSajXilr831gAq2DYypgHTIPWt+Sc8Xpt9NJr00MK/CbEsioxBYBJS34npEkp/fh7rKWpvH42mErTwj8mvn11T6ybEpmi7wt8gdZ3eIanmz5uJCsX6XdFoNI2AFv4SZJkwv37f0hq0pDyKto2saSBjkvoO8kqYeoI3YTVi8J1GU09o4S/hjhfX1boJFVG0KExX86/rDd+Ex/OXUqjjSU2jaQS08Jdw3T3SUsQNQ8GijuZf7xu+CZumzT4aTXpo4S/h/KPH1LoJFWHZdt1r/ut3daE7YYoG5u2Tzxja7KNJzPLNe3VaEA4t/CVQCkzuaK91M8qmYFNkTFLXrp7X3v1q4u8wea+FvyYp2/f34rybnsJ/3OP0u6Ub9+Dldbtq3KraoiN8JRRtinymcevFWhZF1jBgGgYsuz41HYMkT5nhaf5ZE31a+MfGsp09oIEMiwtZuNYR+Bf++GkAwJobLqxZm2qN1vwlWLaNbIPl8+Epumaferb5Z8oQRpQz+9RznYJ6I+4qadOe7qrXfK5WOU72OwTAjv29qZ2vkdHCX0KxwTUlZ8O3vm3+5dxfdina7JOMOKukdTu6MPv6x3HzE6ur0CKfapfjXLOjCyd+59GKz1OvSlUStPCXUHTNJiKN8sDZMt/R/OtTSP71tXg1Evb2FNDrRvNaXsI6Uwv/BMRZJW3d1wMAeGJFddOXVysCPe2h2yCiIBIt/CWobKS8wOkpWJEZKGtJwXJy+xh1rPnH5Zhv/hUfu+0FAP5SO5cx0KfNPrGJM1GyesiyVcITK7Zi/tLNqbcLCJYc7U9TStqTzB8XvJXq+WqBFv4SnMRoYeHPd9RpX3sEb/v+49VsVmws2zH71KvNP+kgf+HNnQAcbcs0CLImCdQA0EQTRwFgacv7ija6+oJJ8z75ixfxr79Z2D9ts3jhn/75X9u4Fzc/sTr1PaJfPKOuONcoaOEvQaX5M08Bxpa9lW8c9QcFm8I06jerZ7l2Xps6qaqzprb5JyHJJu7KLftx5NfnY8mGPf3YIh++3rTdD9L/Pf/vGfxg/gr8+aXSKcOT0Lg7gj5NK/yLVliDif9diozE5v+J21+otFlVoWjZyNaxt0+5S3CbAoS48QtN4G3Rn6zcss/7O47mL/aTxevlwr+nYOH4b/8VD7+6qbIGuhS43+2PrspMs794Zk2q5y3HVbneaFrh/6nfvYQjvz6/rO9ablbMRoWtXEyjPou5lNL8VWYhpvnX66RWLzyxfCve8aMnvddxNv1FrVvV/Xd3FbCrq4Cv3ptOCpT+1vzTGsc3zl+BznkPeq+bQPY3r/D/W0xvEgDY013A1+5d4oV+F2wbZgP7+Rcsu65z+xRLmGzYhCVOArZNYRJ3UivDdLR5Tw9+9uQbTeGjTSnF317bIjXpvL5tf+B1OZq/SrNlsnRXV1/MlkZT6Gebf1ou2z8RXGC15t8AxBnot/z9dfzmubX43fNONk/Lpsg2uObP0juUErS1oJQwYoJIFEg2dQZduZPav/52Ib770DKs2dGV+Lv1xvylW3DFrxfgp0++EfpM1Hbj3CtR61bJNmZuS0un4E2A/aH591e8DtHC34EQch4hZAUhZDUhZJ7k80sJIdsIIYvcf5en8btx2Lav9KYsi+bd74aAOymRG3deLHApnetQ8S+5WcsmB3GSsCkFIYBpllehbI+rrZZSCP7wwjqs3ro/8phaw2TP82/uCH1mmsG+G0f4i49EptlaNk19Jcmv4PpD+PfXynfCiNZ+OW81qVjCEUJMADcDOB/AkQDmEkKOlBz6R0rpce6/n1f6u3E573+eKnlMa87J49NVcIW/bTeszZ9Siv29RWQNx+xTj2UcS5lsLEul+VMYFWxks69ELdkLlo15d7+KD/zfPxOfv5oMbnHScm3e0xP6TOy7USutnzy+Cqfe8HjofspuUW/RChyXRioIPstmf8jpUv2k3GtozTZu7i9GGurtTACrKaVvUEr7APwBwEUpnDcVdh4obZtszzkDqavXjyQ1TYJPnzEFc2ce0q/tS5tbn3wDe7oL2NNdqFtXTz6Q6JaPnIAZE4cHPmeFWmSav0nKT1vB7kWUKWCX2196CtWbND9++wuBzcQ4MCVZdh/E64sScDf+dSU27O6OZfPvKdiB47YfqNzV+fJfL/D+7o+9mFL9pFyHiN4miDNJQ/iPA8CHu6133xN5HyFkMSHkLkJIXUnUNqb59znCv+ja/L983jT862lTAsf+v79XN/dJUu5btBEAsG1/r6v515/wv/xX/oA/f/pYzOgcEfhcZvO3bOq5epav+bvJvSIWddv3O8J/eFs28fnL5cmV2xJ/h12LTLDLNP/Tf/AEfvPsGuX5RNdZQzJBimYf2aojKbu7Ct7fteiq5a6MtfB3kA0l8TH+BUAnpfQYAI8C+JX0RIRcSQhZQAhZsG1b8gFRLiyal+U36e6zkHeXddlM8BZ9/5EVgdfsO/UC26pgXjGUprM8T5N1O4MbroKJmrP5+wOsr2iDuq6e5bqwMoEZpWAyL5YhrdUT/uVgR2j+GeGGdvUVsXZHF74WUYda7COyQW3ZNDBJbEpB+AfaUEUvrKvPPBRAeZr/xJFtdalUJSUN4b8eAK/JjwewkT+AUrqDUsrWiD8DcKLsRJTSWymlMyilMzo6OlJoWpgnlm/F06u2B95jVohXN+xBT8FCb9HGMFfzK+X1M+e/nuiXdpaL6aq1hPhCNc2Oeu3di9E570Fs2tNd8bk+eWonAL/NDOahxGuZfZZjcqjE24d9JUrIsCRyuUx9b/iza5DdB1Hz3+pGokd1Zdn+SugYSgP7NeUGUfKMGpSP/M3+Iu8+33JchkcPzqeeMHHVln3onPcgnlm9vfTBKZFGD38RwFRCyCRCSA7AhwDczx9ACBnLvXw3gGUp/G5ZfPKXL+Kjtz0feI9pPX1F21uGDmvNAQhrUSK1TO72i2fexCNLgpGWzAXNcDV/IN1BdccLjoXv0ttfrPhcx44fBiDsNudp/tzA7CvaXm6fcl1Y2XOOmjeqmWJ4275ePFRmpKwtWR0xRJv/5r2Oht6eV9duEs8jm1Rsmwb6Uhr3yqZ+KpX+kP0tWfn4bXFX9uX0I4OQVHMF9RVtnOMG5X3k589XTaZULPwppUUAVwOYD0eo30kpXUoI+TYh5N3uYf9GCFlKCHkFwL8BuLTS300TtpQlAHZ3O8t+T/Ov02CvJ1duw7f+8hqu+u1LgffZuCfE1wD7Y4m6PYWCGKyGryisZDb/Psv2XD3L1fx9H3X1d9l5q/HUP/yz5/Dp370Uev/+Vzaic96DkW7K7PJlskvU/H/z7FoAvsCTIdqwZfdXtPkXLYqt+3rwq3+uUZ63FHw0fX9o/mdNO0j6ft6dFB5fnjyFdcYkqbZ1txAwV62kcamUcaSUPgTgIeG9r3N/Xwvg2jR+qz/gO/QeV/Mf0sKEf3h+rIcIUVWEJWsZpb5QtfpBm00jeMb0VinB95lWxU9ajs3fXdGY5W1ke5p/xHeractdpYgl+P3za93P96FjcF56jB0xkYkb2jsOlI5vELVNmfAvisLftvG5Oxbh2Td2YM7UUZjSMUh5fhW2TZE1DfS6K7u0USkJzOwz7+5X8aGZExKd0yDpOlKIE+/+3srNaXGob8NmBaiWezL4AcS00ba8oyXJ/P3rwX2yLSeftz2NkFJvI7vefP2Pn+CYe957guMUJnqWsPby97ng2fzL1/zZY476qmfLrWEEJ3OzjHpsTJDLzBYqGR8lsEQBJDvWpkHhv21fL5ZsdBLAdfeVVyua76f94ZigSgBYSY3utNOm8LEOQPUyhjat8J9z6CgAwKhBuZLHMk2TEOI9CBbEIdNw62Gnn7mnijChYLubo4Cv+aVJJSmVCZznw1ZVok+5ytvHSezmJ6xLugKTmX16ChZ+MH+5J7y8vpDsklLFNEpP2r7ZRyak5d+JElji82THvrn9QOA9/hz/+/hqrzB6uWPCsqm36ngwpUyhPLIJxSAI1Ov43fNrE008pmGkKvxr5TbatMLf8gRI6Ydkczb/bkH4y3J41IPmr4pA9uzllHp2+X+74+XUf7+STak+yw5404jePio/f0rhRfgCyf3C2fl44f+bZ9fi5idex61ujpxaTuxiEFrU3MauQdZeZVbUiGsTnyc773cffC3QPpUmXa4yYFPqxdfc9nT6tm5Ze22KQMr26+5ZglfW7459TtNIVwaImn+1Vp3NK/wjNKPQsdwx3X1OJ27lNOs3vncBrjxtsvc6TQGxeut+bNzdjTXbDyRynVM1wXdnBNbvctwx+dzuaRGnKLjyu0UbOW4vRTT7MEHCe5NYlHopneNoxjI8sw/3Neba2Wf5AX5Abaw+RdvGis37vFVHVN9Vua32FCzlZmRUv2XCf+zQFue87rG8ViqafcTfLQfLprjYNf+965iDyzpHqfPLEB05kmjfmSbR/FPZ8K1HePNHKSyJzZ/3jDBc90JGmrbJs3/4D+/vs6aNxm2XnhTreyrtbtywVizbtBcfOXkC2nIm7lq4HpNGtVfczq37evDim7swOJ/Bvt4iTpkyquxz9RWDmr+4iGEDi/coYm6GzM+fPy4uUZuk3m+7E08tzD6PLNmMz/1hkd+WiHZSiea/v7eIo78xH9PGDE782//9t5UAgDuumIUzbvy7d95eLs2FuOHL01WGzZ9SJ2p7/LBWDGvLpu47v6ergKdWhf3m23Km0sMsDmmnTWEKCEPb/CuEN3+UwnOpIwjZ/Bm8aaK/TANPJwjwEK9r7Y4DmPIfD2HL3h6MH96KD844BO885mDM7ByBke1yj5EkXHr7i/jM71/yXOQqQRT+4kBk93cdl3rZsTf7lbyAZH7mPQXLO2+U8Pc1//4dgrLJW/T5X7VlH7a4Pvpv+/7jmHvrc95nsmjlnW5qiuWb5Su93qKNznkPRsYWsOfCBHEPJ5jsCOFfzoYvO5VhELRlTRwoc9NYxWf/IDd3dgzOh7z4kpitys0tpULMI1WtVWfTC3/bBl55a3dkil5W4o3A6cSsSHipc6tel0tUEI6I+JMPLN4Ey6Z4dcOeQMfOZtIpebjRjehlbmiitpKEPrfYDEMUtMw1lU8cZlFng9c0fAGVJEBn2tce8f6OelzVsvnLNGVWE5rdjhv/uhInf+8xAMBbO7vx7Bt++maZktwT85n8MsIv37u3Es0/KqVzOWYfb4+DELTlM6lEDPOsUpg7B7dkwvmP3D63eU8PPvO7lyLb0t+a/95u7epZEUzeWZTiopufCZhXor6zdmcXRrbnIjU/0dacVkRekjSxvOlJ1CL5jm2QdDoqOyfTUiqxU/YWbc/PGgjfP3Zu/rIszuzDvttbtLFlbw+mfe1hPLUqfi6oOEFe5ZgxktAtEZbsuuMofrJr2NdTkBwZpjdCUGcNAwbxhSE/oVg0YsO3nLgL91yGQdCeM3GgN917ruqj+YwZ8PYB/Mnuvx5Zjgdf3YSHX92sPK+Z0phiiJr/7VUK8mpa4c86aSCAqzs8OApCDdGlG/bgRCHFsAjT0BhpCf8krov84Bf7IZ+SQuaT/PwbO7B2xwEkIeSOWUHgmGj2EZfcB9zVhSqrZ44T/vct2oCegp0oTUJkkJd7Xcs27cX6Xf1X8UsmvPtcQRvnzsq+v7cnnsYYla46lzGQz5ieNspr/g+9uknZ160yHAB476bWnJm65q+a5HKmESrWxBQ61sujngEfZLhlbw9++9zafmlnf9O8wl8ywGe5S2iefdyAsShFb9EOePowKNcdbhdc0ioxgQTPE38ABYpqCIKAN1mJS9Q93QVccutzuPQXyXLzJCkQEgWl1HH1NNWaPzMtBSc439uHBej0Fi1vQh87NH5lJVnTvZUit6p7a2flyeuUSNrAPKji6ACya9gfU/iz/iqz02dNgpas4U0Q/Cr3t8+tw//943XpOcuqr0B9s08+Y6ae04aNJzE9dy5jhFZXfKwPEK2IZQw/vcMVv16Ar967BBt3l99XtJ9/ysgenmypzS+Vbdvp7FlJCUdeUxCXjGk9vCR2U36sicJ/ZLsf2GYawTwkb7nplN/amUyrDUXhlunqyfz1ZZr/e493XP484R/Q/P1iLp7Zp2B7pgLxmQDORr5sYo4a2Lz5oj/zOslkZRLhJ9P84/ZDtlH+2PItoc8ypoGWrOn1RVGJUk2IlaTbMAznmaYtBP0N/uD7V7xtsvJYtsCNmoANQrDzQB/2dBe8YlGVrIT5ldjEkW1lnycpTSv8425yipp/0aJSQcJH1LIAkQumjwGQnvBn5+kpWLhv0YZIIRXQioWfHz/c70CiZwKzZSftqiqPnKQw7ZYX/uy9qQcNQkvW8IQ//wwtm8K24dr8meZv+yYiyeA76buPSgPc2HkfXLwpZArkhV1/bv3KhDdf2KT094Ovt+ztCSUIU8HuvSxvFeC4Ofe4fVH8HXbvzjtqTOD9cpQBf8MXyGfT1/wZ/P7SmhsuxJypo0LPtpjAxZetgs/54T88cyitoLfwCsr0cUPRrojeT5vmFf5CP1JpcXu7+UpCFAXBE4XBC3/2cWvW8c5Jq9Mygfr9R1bgc39YhGdWh4tz822V/Q04+cYZBiGehrXzQB8++NNnpd8phSj8y43oZPdKZvbJmQYG5TPehMwLHrbhS4ifkbG3aOGAayf+77+txLw/Lw4cDwDzl24JTaI2dXzAP/P7l/CzpxwTHtP4eA2Oab+L3tqNZ19XP4tyqERzB8Krl5O/9xi+82A4U7osEJyNhZxC+OczhnftYjtZX/rWRUcF3q/I7GMQ5EyD2+hPd9qVZTMVf6Mgav5wPJseWLwxtPoxveJPvd7x7JBVW/bhfx5dlah9vObfmjXL2jwvh6YV/qGHq1iW8ZtklDqdWJY6gffEYcKKTQhp2fwZm/c6S2tV5k5A2AwVrpXv7BnDd/XkUwQnHV8q17ikeIJeYvbJZwyMaM9hhxvcZQvXGPL2KdgBu/UfXnwrdE4gfK02pVITIBC0+bNB+Z6bn8Hcnz0nPb5cypVvcTKT8rAEgEePG+K9x5QbVcGafNaUelwBQYGdzxgYN8zZaymnP7BbbRgE+ayB3qKFx5ZtwaRrH0o1Kl2W5DHsXuz0JXYdNnVSK1/9+5fx55fWB47lY368DWL3vnzwp8/iR4+uTJSZk5cf+axRUd6sJDSt8I/riiW6x/UVbWkBFz6L5n7XzsyEPxNoX7lrMR5YvDH03aR4WR0jIzy5v4W+EoieNfzCE5XYsMPJ1yqrfZqTuHpmTQMHD2v1YgqCpi3qFXPhzT6qSZ3XRMX7SCkNrdbYIbwZsNyUBXGIerZRy37mehlXOWTOC7zywvq30uwTofmzlyYhWPGd8/HMvLcDAH7yRPLa1sENX0fzf3iJ42K5aF38XDulkGn+08cNDbwu2hRHfP0R3P3yBgDOdbL0KDv2B5Uw0ZUa8E2EBW/yiD8Z8pp/1nRKr1Yjf1jzCv+ENv+5bk7vok2lQpLXnB5d5myUsQmB2az/uOAtXP37ypKoffhnz3kBaZQCG3Z3419++SL29qht02JHywtJ01Qd8b5FG2K3S9wHKbeKUx+n5TNYAfcjxg7B2KEtXmFwXgEKmH3c73YXLKWWVGA+8yTcFywbWLxBLly27OvxSgv2pxdG1NiOWvazPZu4woXl6gmkKyFOP5u/VO7L3pI1PfdDlRAyJWMkqcYa3PB1Vhu+q2Xlwo8VZPrOe44OfWYaJJAGQzRbMbMPANwsTGwBN1FvgzhoNnrlrfiTF6/5D3briFRD+29a4R934mUbfge7gwQIZvxjTBzZjhXfOS/wnmf2ifCbTso/X9/hhedbNsV3H3wNjy/fiieEikP84LcoDZgBeK06Y/qunmIH5/PIlEJVZ7e7z0LnvAdx18L1sq+FkNn8P3DieDx37Vk49pBhruBhm43UG0yWmwfGIATDXW+mnQd61cLfXZkYhHh94Z3HONVE71qonqS37O31PC7iaP59RbusFUKU8I4a+MzMFbd/jx/umGX4PSubOv1MlUWTd/VU/Y7YH4DkKyWb0/xzGSOwGkvL7P+J2RNxjFsuVOT2S0/CTZccByC8YU2przSIJhxeEfJX6c5rtjf2sdteiNW+1Vv34YHFm3DcIcPw2rfPxWA3yl8L/wqIu2xauWUfJo5sCwlMGWIBCLakZsXF08aiFOtcl8yDhrQEPhM3fPnOwreTj/CtxB2N3/DNmsTTTtm+xI3zV8Q6j8zmTwjBGHfyzZqGJ7htSj3ThOPt4/j5D2nJIJ8xsG1fr3Kjkc/Lz66fnWvN9rCbK5Nle7oLGOPe6zjC7PQfPBFIHRGXqE3NKMHH7rdoEpPx1JfP9FanvCdRqQ3VfMbkzEsKzV+yL6baR1HBB3nlhbQSaYym3oKNfETU/MHDWnHRcU4mUXElS6GugBfISMuUEy5VRRLO/qFTu/fEicPRlsv4BZiqUEu6aYV/X9GOlSBpzY4uHNoxKNCZVbnyRfgN3/6wD1NKvcCdkNcF99K2gT6us4hJ03Yc6EPRsiuq6MXfn3zG9DQlJlAPRGxwUUrxj5XbvAAvsY08GW6PwrIp8rzwdzd8CSEYPSSPrft6lZ5W7BwGZ/Ziz3VIazhfPNWdAAAgAElEQVSHEru9vQUL7W4VtzimlU2uiSopoahsRZ8They7f/IMXl63K2DKUpmnchkDV50+GTnTwBmHj/beFxWV4w4JasYtWcNbfanMpzLhn3QFzKd3YMK/r2gHPlPx54Xr8cKbO5WfU0rRW7SUHk0MlihQvCf7egp4+a1dgfdmTR6Bf1xzRkA5JAhmmC03IaBYNrZQhep7TSv8e4oW2hWlDnmKbmER/qHJNnxleDb/ot0v9mHR5h38LKj588tWXrCySkw3PLw8UJWJcfYP/4HFMQpZBIW/AZs6GifTIg9EhOb/7bUt+MTtL+C2p9+Umn14Mm5cAqVOMJhX4o+Zfdx2jB7cgvsWbVRmsPQGD/EFLTsXs6vK6C3a3nP93kPL8ciS9KtLAWHhppIZsv2nZ1ZvD6wOVIoHIcChowdj5XfPx7Hj/Q1OceL5xruODLx2/PyjzUtxzD4L1+7ERTc/o/SGY13W5DK1yrKVyvjSn17x3JZlFF0HAZWSwWMaJCRsv//ICqzcEkwGOWPiCEwc2R5wftjhJh/0VzHy35h9/WO444V1yjb4sRfJM9aWS9MJ/309Bdzw8HLs7ipI0zSIWDaFaZDAUjiuV4yv+Zdn9y1FHzdoQhtSgtmH/zwvcaN8fMVWqY1/9db9uPGvK0u2RRT+APDFOxfhT66tP8rqxT57ZvV2qdmHJ8Np+pYdNPtQN70DEIxlkOFr/r5ZhO3lqOo7Uze9B28fv/+V8ry3KKVYsmGP8nNRsVMNdtkk2V2wAqYeleJBuJClLHe/Rfu2aRA8/ZUz8dSXzwSAQISv9LwkHPHN2sXz1XuXRmbU5QVmRhT+yl+PB3v+cYR/llttRsFWrfylb3c9gX782Cr3s/B9KVo2Nu3pwbV3v4qbHl0pNbuxdrI+Wm4EfRKaTvgXLOrlH1G5zLFNMIB59xhYy+WOl234yuBdPftD+PcUbW8QiPbHgOZvBzVJvsOzw3gff5FcjMmO79TMc+TeRRvxgxi2fmZG2bK3V+rqyeMXnacBm/8jSzZ7Zh+gtPAveAOVM/t4hcLl32GDmxf+cVaPMq767UK883+fxoI1ctOEqPnPUCQTlN2nPd2FwGSr6nu8kOInEXEz0SAE44e34ZARzka34+ppK/cGVHZtMWEcU6KWbtwrPd4z+7h1mQFutVvhji8zccYx4cZN0dzneZCFz/mY65Ah+zV+cr7p0VXSSG42BNkkrTX/MuC1OlV+fL5fMc2fT+Gr2vAFgP/50HHe360BzT/9mZq3o4v2er5vRGn+RU4IqlD5e/PwgyiONsXDF2SXuXoG2mKwzm+7wt/53eff3ImVW/Z71xFlumHfB5jwD16DapOYDVLeLTJJjQWe+Usdd+D9vUUsXLsTawSTmyjbPjjjEOl5ZIrIhl3dwSL0CrMKL6SyAeEf/HHRfs82SVUrCpm9HwhPQuy4L9+1WHZ4YMNX1Pz7KhR+Yj3kKLJmvMAqdj9U56RUnvJavI9RJVCzXqGi/tf8m66MY0umtNbGazRF20bGIIHgniizz0XHjfPMJ63cICknyreU1wXfpiizD3P1zJkGvnDOYZg2Zkjoe/zgP2b8UCxe75sk4gh/3rdZFjQTBTNRFCzK2fzl52ADSzT7MJi5IWqCBoKJujyXQrakVqj+bMMyHxD+leVZ4bOnrrnhQu9vUfOXmSiHtmaxeW9PKNXxxt09mD6OE/4KxYO/Q7mM/0oULCHhz6XMlqESfqLZR5YgkYcJSsMg3nN90d3ErTRlStEz9Tnnveuq2dilyJ2UMWOafYphsw+PTeVeOqJskGVTZRM1M3tqb58y4G2RbECJSz/+tjLNn9+wjGv2yZoGchknLL2c3CalVrZ83qGoDV/qav6jBuXwqTOmBAZnn6et+N8VhXcpQSp+X6W1q2Duqn1Fu6TNn9/wsml4YmKXppqw/InGT9TFBC07t2qJzwZpIEguoi+UU7rQa6fw8FXmHQD4uZt/iLG/txgw+6jywfOrPX6ylZl9eFj/UJ1XNPs8+sXTAYQ1/1L9ij0rk6vLvM9d7VYq/H3N37mvMzpH4JwjD5IemzGMWOO3r8Qq2rKp9DyiF1SUc4TX/7W3T2UwrU0cWPzAK1hOLp/L5kzy3ou74csSUhUtdXk7GX1FJy6gVBTy3p6iN0GICcee59zcLNsZSFFRl9u5EHVxE7GUOxwQnBCTaP4rNu/Dt/7yGgDX7OMKWNU99jQf2zX7ZEThTwL/i7BB4234cvZc1m6VjZxpuoHJLeIZqXLbx4HvLi1ZI9KUJgqU7oIV6MNKTzPuFmU5zV/UKkVNnrVFXFGwLLZiP2tVBDuW8prjTTPhrLHpav5RZEwS6/fYZBgl/GUxF+LziVIaPFfPKuT4T0X4E0LOI4SsIISsJoTMk3yeJ4T80f38eUJIZxq/WwqWdZO3KQIym7+Bt03t8N6L0vZ4TIMgYxLHPp1A+B/21YdxyU+fLenLzOcd4jvnNXctxuNcxC+z+cs24tgg4CcncaDFMfvwKyqV5i8zY7253ff0KFrx/PzZsTalng3Ua4d7jaotDD+a2df8WbMGtzj9YZ+k6IlNfW2Tv74fP67OWaMSGHEUAf5eHXbQ4MgJWHyuXX3FijZ8RZuzeH527Lb9vpPAyPYcJo8aJD2+hUu3wSM+OxHP7EPCwj9qwzNO1k/mIBHH5s/HlkTB+uy44fLCQUXblmv+gtknqk+V2pdKk4qFPyHEBHAzgPMBHAlgLiHkSOGwywDsopQeCuBHAP6r0t+Ng1fBh4Y9YNbv6sJnfvcS9vcWQ8vTOGYQwBGazmZRaS1eZMHaXSXNPvwmNN8ZXngzmF7YdjeaZB09TqdOuuGripqU1b3l212wSpt9eG8fy6YhLYt54qieEBMafGUmNsm25TIgJByuD/hunkA4klvF0FZ/09kWrrMU/NjOZ4zIgETxsfYU7IAroNLVk9/w5Z0ABMEi6jrsGWzgqlNR+AqA6OYpW1FRSvFKifgRNndKNf+IexhHLi5yfzvOWM4YRuQmLOA8629f5OQImjV5pLxdtnziF5/PkyvV9aZ9b5/G0PxnAlhNKX2DUtoH4A8ALhKOuQjAr9y/7wJwFik3FC4BIwf57oBBbZXi2395DQ+6dV/FpWGpjSpGLmMgaziafznpHUp9p6dgeQmu+GPFcn227Wg6MuF/1emTQ++FNxsNdPUVccr1j+HpVdulbeHP3KIQ3LIoXysgFKknnNVBXr6fs22HBVOba8pjvedyzlzH/14g9xFnAmjLmp7w5z23LJt6y3rVykZc3X3voeXe33zyr1KCRGyfU1ZQPRxkPvWsghSQXPMP5acXzs+ewRYueplVURPPC/DC37/uv6/cFjA1yvDTQycrExpHMLIiPrE0f5OUDNL83FlTMYKrkCejaNs4iksAyVYoojnsbVNHKc/he7s1gOYPYByAt7jX6933pMdQSosA9gCQT58pMnKQ+7BI0P5o0+BsLHa8uJp/zjSQzThuYuW4JZcy+/AufHe/tAH/+psFsG2KA4KG7Wv+4cf5sdmdmHNosLO1Cpp7zjSxbNNebNzTgx/8Ve63z7c1rwiSkmnUfGAZc98kRB0GH9zwDWv+paJ/mCmGyQfqRgYDjhBty2e8SeqECcO573Gav+L6ogTSI1yGzDj2WhrQ/M1IzV/22XZe+McJ8kpgVmLPYHd3UHirTsH2vvj+KjOtiXhZPaVmH/U9FCevdTu6cO/L8gy18Wz+Rski6nEmEcumgSp6TID3WcFzD+HclDvceJW3TxvttoWZPRtD85fdFXGUxDkGhJArCSELCCELtm1TL43iwteyDdr8g4nQRKEZd8M3axLPXliO5h+1xzRz0gj0FGyvZuqit3Zj/tItnjcEj0Wpu3chPxffcX90ybFeKttj3Zwulm17niW8KSPQVu7yVIKkVAELr50Rki7DuWPKTFlMy2WCTbzrXl4gLlKUerZlJ/CvwG0GX3fBEQAc+3Yps0/UMw4Wp0lm8z9m/NDI8oGyDcYdnD2eCa7p44bi/z56gvc+/7Uo4SWuLNjzDSaD84+TrVLyWcPbyNx5oE9aPlMkasM36l6LpsyLb3kGn//jIu+eFiPGtoyMQUqu1mSrLxFWcIjBbP2i5s8fc/DQFhw/YZgXYOd7+zSG5r8eAB+hMh6AGBPvHUMIyQAYCiAU+kgpvZVSOoNSOqOjo0P8ODZ/uXoOPnlqJ4a1+cKfH0D85h4Q1vTjunoSQpA1HXthUpu/0w7/OwcN8U1U93z6FBw5dog0KvfMG/8eeo9NPqqOzg+s06Z24KozpuDK0ybjj1fOcqIbKfUGulr4+23lTQ48ojlKhKXJjRpIJmfzt2lY8JVanntmH/d/PjWvQUigKI9BgCtOm4zTDuvAuh1dUlfPwLkjnnEwiCq+zf+6C47AZ98+FWOHyjcR+Wvi4TVrdk+uv3g63j7Nd2eMa1gVJ+OMp/n7wn/6uKGRk3Zr1vSE/5+F9N6jBsnNJeVu+Iob7cy8xO5D1KpeRsYg0liJU6aMDBxTiqIV9Pbpk7QH8MfSy+t24ZX1e/AyV7im0bx9XgQwlRAyiRCSA/AhAPcLx9wP4BPu3+8H8DhNu1Anx/TxQ/GNdx3ldSiCoADks0sCEptngopXuYzh2qcrE/4dQt1dlTulTPAW3T0HVbMDGUtNA225DP7jgiPQkjXd0HbfU0O16uGf1oXTx0qP2RtzqR8lRLKezd9P4czDygaqYIJXTH8BOPeVD9piGuzowXls29frB3mpNH9BIPH3KsqbBnC0ex727E+YOAymQTBhZBue/sqZuPSUTgDAe447GN9/3zEA5P72/CqLrYZyGUNaZaoUKs1/j6sQ/O7yk3HLR0+IXD0Mb8thV1cfCpaN/3pkeeAzlc++zWv+CSrFieY3du/Z8+OFbXybv8RZgXvecVI1s8BEhj8ZWcJxzv+y3E+8q3N/U7Hwd234VwOYD2AZgDsppUsJId8mhLzbPew2ACMJIasBfBFAyB20P+AfmOjqyS/FQhu+MbN6su8m8fYRI3MZvB3QEf7x21BwO51qxcLfB1G4m4TAsv0Na9Vym6+spNr4EoWe7Fw2jR6QbOL96T9ex6sb9oQ0sk+dMQUAV2hb+AnvOrzskP5S3CAIaf6A40HUU7RK2vzDFcGoVyCG3+gTNf/2nBkSxKxN/N4Hby+ePn4Y3nGUo8X3SiaT/T1F7x4wL6usaQQEeVwVJrzh69v8CXE04MEt2Ug321zGwF9f24LHlm0JCWeVFs/XA1aZ72Tw56eU+nEJrpDlN8Djaf6GdILiA63im3381yrNv7do4bCvPox7F4WTBvrpHfrf7JNKegdK6UMAHhLe+zr3dw+AD6TxW0ngOzX/8CiCA1TcnIqbzx/w84LEtfnzh/GyhPmgA87gihNIZRAWUu78vspaxQfliBME0/zZYFNtavKKiCp4R1z9yMxAlk0jzRHs3rNEWSxlLgBMGzM49NsUzvm8YDjbF/peuwJmH07zdxvCTBZMQ1N5IvG2ZFZT+NDRg9CWMwPXLmaxzJhGqH+w5qm0cwL/Psvy5PdZNkYNymH7/j4v/YPYb+Nq/uENX1fz7y6gLWt694mNJ9nk/aqrxT4l8RZTmcHYPeGT75X6DhB8Dvcu2uAI/15f6CfV/LMKb5+A5h9DF2M1Jxie5i88vze2HUBf0cbCtcF6AU5bnB/66r1L8NFZE0v/aAU0dYRvQPhzfYB5xzA27enmv5ZI82fCP8pz5+YnVuNPCxyHKL5T898xheW66JEjgwmHe17egBfW7FRq/rxQCGn+hjPw/GpfiiW6m075uWvPUk6OooCTLaVtRTyC11bh3hctig+cOF55PBAUcn4hGP43nf9NI2zzB9yatUXb06BVmj9/eaz/ZAzixXowxOLjWZOEJlV+NaKC3WdVRGjnyHYAvuYvxk7EtfmL3Yb1/+4+OxAf4OVVkjT6EjcxncxkVlREvtq85q9Ywcng7+X6nd1en5aZWeKlLiFSd9kpHe3cMaVlguj44W34CuOAj58QSWJyrpQmF/7+3/wsTmlQ8G4VNlbjaAuMrOmYfaJMdD+YvwLXuJkN+Y4bjLr1G0sIMIjLJnn2EX4VpsBvu+18YLETr6Bampqc5ia6WJoGCUQmqgadTYFpY4ZgzNAW5eQomkVk2lTBKuXtI3h9UIpPnjpJeTwQNG94rp6ct49fZSmYqI3dC7YaYLmUVJo/f32e1mr4m/4Mmd+8JXQQz/1UpfkTrkqaIhfMRFf4s5Wr+FzihtKIApsJoN6CJewhOP/LxseHT57gfEeR4FCWq4Yv5iIK/4JNsXDtTnTOezBUbIjXpNn9B3zNnzcVxhHa7blMaPX/u8tPxn9yhd/j2PztkLeP3OwTBbuWsUNbShxZOU0t/PmBxTpfLmM4D4l7Hp99+9TA95LMvp7ZJ6bNn9805NsQrAtKMITzumlTZCcV896UKgUo+5yZfZhwEjXUL9/1Cs676UlQyhVTV5qGSi/d+4p2pP1UFGCqFRATbJQGNVzR28c5xtcwZZo/y02z17WjxzFr8YFjOZMEvDPE+zOoJaPU/ENhDMJqkBB55DTgR7CzVB/laI2y+8v6Yk/RCgh6JgBlK8yWEmmgZTZ8z8/fCO4pOcfb3nX9N1dsqGDZuODHT3mvCQnnIuI3yOMI7SESD7dTDx0VUMDELvHRWRNC32E1KNg9/c2za3H3S+sTCf+WrIkffvBY3PPpU2N/p1yaWvh73j7Ez93RmjUDvt+AUzyZp1SEL+8Omc04Wp9M2MjgNSBeW+TPaZDgHoAqp/xBg4PagUqLZPZYWSdkG74qzf/OBeuxfPM+J7zfPb8qf7w4Acq8XnqLVuSAlKUXlh3OvH4mjWoPaLh9orcPDWrZ7RKbPxNcTyzfGvnsea2O3S/T8AP9GOJ9OOrgIaGJ0Y89CF4cO4q9mzUMZX1kcV8oToK+8DnC38lwgXa8oI9Kp53PBLVvEZkiYEWYfYrcCvEfXDqE7wueRAYhvreP2y/5+y8GqsngxxoP36/EFcR33jMdE0e2Bd5jjhPs/ftf2Ygv3vlKrIA3notPGI8xWvOvjIDmz1VpUhVdYIKh1M7+c9eehaXfOtf7TlevFThf1N4vrwGxNh0yohWfP8dffRBCAh1Spf3+6JLjAq9Vmr+qzi3Aa/5so1R+HLP5A04islGD8oHNUyCs+cs8KHqLdqSdW9yTyGUMaZvOPeog/P6Kk/GxWRMDZh9ZAXAvyRsB2vISzd+9v5v39niTx8Ofexs+Pju44WYpNH/R5m/bNGB/d0xroubP2qAy+/imOpXmLwruJI4Kftskwt8Itt37W9j45WH7JKpAP1ERONBbxN9e2+Kdd9rYwYHPX1izU7ppIW6SGhLNn+8vR4wdglIMKVEYCJBv+IYD05znOqwtGxizUVX0aklTC39ZXvvWrOna/MPH//wTJ+GcIw/C4BLVm1pzpqeNt+WcdAFxE3vx/rusTd9811GCq2ewQ8o2IC88ZixGDwmWMkyyV8F/h68EFhCagc1pXyANymew4Ktn45QpwbQR2/b3YR1XDlMp/BNs+PIpGHgIIThlyiinEAgnJNjqxpvMuPdasqZU85dNrkeMHRISHHyfYc9RZvO3aVALzxjhMoGqDV9xostnjUB2Vx5e8z/7iNElUyjLkE0Y2YB3GK/9qoU/K6Kk0nJF18Vr7nrFM+sYBsHowS1Yc8OFWOIqVQCwfX9YaMomS9Hmz+7tXVfNxqhB0eU+AWBIa3C8s9TVpX43nI/IdmNTSGB1JLuOeqCphT//cJhwa8masCkN2IEZs6eMxM8+PiOWTy9jUD6DA31F5UauiEzzF700xCCvFokHhUlIyERRjs133c4u3PPyBqmf/4FeX+N8cuW2kKASX//4sVU47QdPeK9lUZM9BStykmKb2GxVcc25h3uTHPOpF+GLdLAJh1+JMRtwS8aUa/6KWs+ieUqVLC6fMQLmDovSgACN0vzFTdnDDnLSJk9ww/3bcxllRDWfXfWyOeEEfiI///iM0IQmexb8vgt/XVHePkxBUU1UYsQqvxrl7/OgfMazp//++XXe+48tc1YJoYjvgh3y9lHdWxV8fMU/rjkDP5l7QugY2T6H2BZWo0OsCRzl3VNLmlr480KcCdrWnGPz593/KqE9n4FNhfTLAc+i4N8yzT9crYoEtH2Z5m+QsLCXTRJxYW3mBdx+wctE5ikUxUdvez70Xm/RjmXz7y3aGJzPIGMaGDUojyXfOhefOfNQ6Xdu/MCxuOOKWd73gKAJik1CLVkjoPkbgs1fRFQC+AG9ZW+v195hbVkvNxL77axp4ILpY/Drf5kpLRBOFZr/R2dNxN2fPgVnuom+BuUzyshpPrtqnKDAs488CBccHdRqZRHdKiUi0uxTUvMXAp0Ejx0ecQ8OAObd/arzh/DTvUUbuUwwpXQcN1qeww7yTU6jB7dIlT/ZVhC7T8xEu2zT3sAKmVGvZp+mq+HLYwZs/k6HcGz+vkmjHDspz6A88xSRF14R7cS8NsxMBWEXvaAgl+WaMQwSGqQq//ShrUHhxJPLGG5lsaDWBISDtEKaf8S9U2169xasWGYfJ2gtqBGqyGUMTBrluD16mr/tt4MJhZasGfD2Yd1D3LtgiM3kJ8b33fJPAE4fG9GWCwR2sdKg/+8jJwJwvHHUZp/gjxBCAqauQYrNSHY9DH71cv3F09GhMHeIHmJSzZ+TdHyzWTeVacGmQZA1iVL491lOnet//9NifPncwyNdY2X7EGwssyPHDGnB3p4CegqW753kPmfVZrqKjsF53P3pUzCyPRdaBbIAQpnCwto5pWMQ1u3swpodXbBsG1kjKkF3/dDUmj+Df25swLBxfNFxYvbpZDA3sT8v9FPK8kt8vpMXbRqoy8smJFG4G+5AYsgCZ2RmH1VCst9dfrKy/Z863UmXUJCYfcQJQ5TnKg2eUnktUyDZhm+SiZn3Nrnt6Te9yGAKBIR/x2A/NQUboqoNdVEo8a65fN2A4e057OJMM2JCOqb583sgfL6hKFSeXux6GPw1zJ05AWcr6tUyRYPta33pHYeHjuEnXSuwcnX+V634WjKmcsO3YFE8vWo7/vLKRnz9viWR7pgql2SAL+PpPHNH8xfMPjHvLc8JE4Z7cRM87D7Jrpm1k6W0tiyKouUoLaL2f/yEYbHbUi2aWvOXwbS8fb1FXHTcwfjPi46q6HwndY4AENzUCVSvKgY1fz5TotrsE1w6yoS6aRB3s9PXzlQJyYZHFKFgnZq1hdfYxeXqXsGeq5LNBYsqE1Pt7urDQUPUbmwy18I4sH2Tx5dvxdOr/RQDlk3RzZl9Dh3tL/FL2fxV+Xh4eoo2hrZmcaDPQtGykTGdOBJ+Xs4YBPt7izjsqw/jH9ecgYkj25V+/iK888EVb5uEoa1Z3Oj6vbcqhH8UOXdybcmZeJXbXFXB94ddbqI3mVkGcDenFRYOseYFrxSJir5M0LL75P/v7Is5e0gsDUbQ7JNA9itpyZrY21OUtokvbsP2dWzq1AQXj660IH1/0NSaPxvUH5zhZ5zmB8m4Ya1leUjwHDysNZCREwh6yfRyhRyKtp862ckrr97w5ZHZpJlg5NNWqzT/KA2at7EDQU1P9FIQa7SqhHN3wQpMejy7ugrR6R0kroVxYNe+fPPewPuOqc3f8OUpafMXN/Rkwr/PCpSeZL/Jt52/Tyu3OOYhdqpSl8hHJF995lScfpgf7c33G1VpTRGmaMTNqcuvBN97/Dh87Z1H4ip3tSgSVf6St/k7pTX9z+Jo/mIuJMPwNX82QfUIG75JNH8VrG9I+6z71pCWLDKmHy8jO7YaZRmT0tTCvyVrYvl/nod5500LvMeo1N7PEGt6BuvWBl0nmSllcEuW0/xFu2/w/FLN3z2I16JVQiyykAdhmr8bIMP1UVHzF1Maq4RzT8GKLI5RqrBIVBoBFRnTgEEQKh1oUYqeooVcxghNVqz5arNP8LUsP01v0U+BwGcU5X9LliKB9ZFStSMG5X2X35wQ8Ma3L67m7wv/eNKfF/6tOROXzZmkrL+s2nMCnHHwhxe5gn+BvYTSjgRU0OYNTvNnl3Lrk2/gfbf807f5pyDd2NiTTSRMqZg9ZaSn+bP9HlH1Z/dMVS+jFjS18AccgcgPxMASP411IYA2YeAF3DmFsH8WhZjN+NWD2IaVwXVsHtmgYgOELwKjGnxRUatMgMQx+0SVMeTp7rMi85GX0sjYaiypi5yseZQ615aVCBRmWlPVMAibfcLH9BRsz+zAp5HmJ0YxaR/gOwWUcs8dxGn+uYwhPVfUNYiwDd9SJUQZMR85gGjNv69o41HXXZMgmM4hjheZuOoyCPE0f36CWrh2l+d5l4bmz8aU7H6xMdOez3ixHEz4i7/8g/cfi6vPPBSzFcXfa0HTC38RXlDLBEI5iDbjoiKFQ9H2y0fadtjPn3g2REH4SwYVO4bfEFSZfcwIweBp/pIiKNv294ZSTfNEbeqqzD7Obyo/ctqSsn2UbcKpUPmDR5UWPNgNvz963BCviI7lZRQN1h7mNX/2NlsRlkol0h7ILxOseGUGzhtT+LvfiSvU404SgNzdlGXG5BPbMQ8aFTLhL5pyCHFMXT0FK9RGlqgxjeHNxp405bMXO2TANAxP889INnw7R7bj38893BuLowbl8cJ1ZwEIxqlUkwEn/Hnt+NJTO1M5p+gqyGv+vCArWtQb9DaloQ1fX/MPnl+m1TGNPc+t/VXL8Tg2f1lahO37e3HChOH4xaUnAQjXblWdlYJGmn2Yj7yKKLfOcijadllaYNSG76zJI5E1Cc47eixMM6j5W3bQzs+7LrIzsIk/mymh+QuunnybyrmmpGafJMKfKR+8EnLLRx131yQmb5kpTIyL4DV/cSJje25xJ8Qo2IQmq6ngxQ5lTU/zV9n8RfNR1nSimt+8/gL87OMzKm5nOQw44c861mEbsuoAABzLSURBVHlHjcHgGDk94hAS/kpXTzsgZEOaP5hWE+w8shTKTLjwkxlvH+aJsp2Hhb//WXefhfa86ZkmxLGkGlyyVQ3PthLh7irvm3LpK4bLQcZBXC2Iid1YcjnR5u/ULPC/x/+9ZvsBbNjdzcWZlLL5i8Lf/7uciG5m9okr05NUE2R7TrJSkkEzYLhyF0+U5s/6HHF/z7H5B8/G3JbTMPt8691H4W1TR2FGZ9jDiZl082451IKb4JFlY+VhfYm5erP/05igymXgCf9+KJbAOv1I16WS9/YRbf5+jVlf4LLB4m9mlW5zj2vX7OPMK6rshFGaPxsgzJNHDEozCOFWJqJtVn5Om1Jv9XPLR8Kh8qU8H+JuXsalXM1f3NAO3BuuKI3pCThO+CsyQn7rL6/h1Bsex59fcuJCStnq24V03rJEa0lgvxdXo49awYl42q1ks5v/Pcfso/59WX+dPs6pgcx/kncDFMVrYeMvDbPPoaMH4zeXnSx1pmDdoSXjaP7b9vVix4E+mCS4Rj6B8/FnGUoPKJL1VZMBI/wf+Owc/Hju8SU1rXIQOz0vJALePpzw39tdQFefE51ISFD4i9qAbDAwu2YXl4JBZS6J0i6YMGGbZGwgvbhmJ97YfgAUagHFvvvNdx0Z8GKgVB29zD6PIm3hX7DssjQssasEcvtw6Y7ZfWDeQE6pSrnNn/Hm9gNS27BIW17unuq0L/k1MeeCuDZ/lmMoDux+ZAyCK0+bjGPGD/XuTXdfcBJJovkPb8timFu7gPf3Z5q/WCrASlHzj4L1+ZasgYxJvHxFyzbvK2s/ptoMmCCvo8cNxdHjhuJO3t0sJZiAY5pYIWD28Wf4VVv3484F6933bfz86TcDAlvsrEcdPARLN+6VduIte3sABHMKqdIURMHa7OVFcdv+pTtfAQBs3tPjXZ/YjNas0/YWd9nL4E1a5ay0olwGyyGJ2YcvTi/mpuctF0Uu/QS79oDmr9iY5Ylzb0JmH0Hzf/KaMwN9rBTMpBbX7/z3V6ijw0X8+2HgPy44AgCw0fXYEmsSJNnwzWUMrjaz//2WbNDPn8EUrv6WuUz49xTsgFJZtGy05zOe27G4WklS3KU/GTCaP6M/zD7Mrm16mj+fvM3vmP/uClQeXqtmQp5pmL+/fBbu+8yp0ohYpvl/891+hLKsIlEp2ADp9jR/1hb/f9axxcH0+XOm4vI5k/DeE8YFJigKzuZvGrhsziR8971HIy5pa2wFq7TZ55wjD8LR44bgma+83XtPNLl87+FlnqBhkZxA+Llv3tMTtM0rhH8pTx8gXMVNdCGdMLItELVcisHuvlApt92/fuE0PP6l0wMZL0vBujK/2GPXzpd3TLCHDMAZX5Yk8WA+I/f28dJt97P0//zZU2EQ4PAxg0MuuKpVOFuV/OiSY/u1bXEYMJo/o9IsnjI8m7jb6XlTD28zzZgEoqmP3xC9/dKT8Otn12CQO+CHtmVxbJtjL1xzw4XonPegd+zFxzs5iSaNasfLXzsHL7+1K1buchF2P3qECF/e7ZTlThEH05CWLL76ziPd8/jv8zb/jGnga+4x192zBADwubOCZTNF0hizw9qyIHAiih2bf/TxMo+LkwWf7De2HUBPwUZrzgx4dfgbvo455/Vtzj+GyjwTRxFpF80+Bv938hsVlSiOh890GRc/5bPfSNGhAFDX+VWRMw1uVeW/T+DYzp9ZvSNwPBt//S38Tzl0FN64/kIAYXdelYs0u45ThVoYtWDACf/+sPmLZh82uxctG/92x8vCcZb0uwAwc9IIzJw0ouTvrfru+YHONrw9h7dPi/YVNg2Cj7pFtsX3+TYzsw87u0FIwMNCeX5e86fUO59sU/IL5xwW2VbGlaeVzlGvYtHX34E/LXgL19y1GIUSfv5JONBXRGvOhGXbfrIxz+xjY/22rtB3lJp/jNQikZp/GcItbTdaHlnKZ0/4cwpRnOvmyZoGLNsx77y+zc+eqto0TXPDNy6ijf+i48bhuTd2Oq8lIyduOo7+ZMCZffpDGRAjc5nJQ8xwyJt4Lj2lE0CyuqusyEWW2ySOy+vfuwDfuihselH5snueRwafh0b9m/xnNvVXEOXMtexMxx1SWSZENiDjmH3iwtJcW1LNn0oD1FSrzThCcHA+g0NHD8KNH3DMBMEN32RtB9SxIGkgq/Ql0/yTxA4Ajp28aDvpIdbv8qO+VR5DTLuu5karuIqbO3MCfh7hv68KyKwmtW9BlemP7uCZSCTePjz8oGAPP8lg/M57pmPNDReW28ySbQLCnhLO/8HVQKnz2DZF0pzqPMHfjs9lcyZJ21S0yvPzBxxPJn4SYhM6i+Tkf8eyqbS4vWq1GWfjzzAIHv3i6Xj/ieMBBGMgytH8GaqqaJUgboAD/rXzm9KygCkeUaY7mj/Fy+v8+r3HHTIsVBqSUaiJ5s/VQHDHkBedLWmHFv41IOFeUyzYs/X8vd1OKW6qscjWqaMHeQ+/PzagkyAKWFm2yfHD2zCiPed5cMjgJzGb+hGdvCD4y9VzcNdVs0u2if120v2ZS046JPA6Dc3/0lMn4aZLjvNeM+HP2/x54S8rZqK6jnJqu/L+5uXuX73xvQvwv3OPL+u7UXhmH8nqhNf8S8UOTBsT3G/ImARFiwbs/f/5nqOV5ylWyebPIysZG0U9uH9WZAAkhIwA8EcAnQDWAPggpXSX5DgLgFuHDesope+u5HfrDVFY8al9Zdxx5Sz8sR9cTsshpPkzsw+nrrRkTbz0tXMiz8O7mVJKfbMP18mnjx+aqG1Js66K15LhhD8/1m792IlYuC7UTWOdlyW7sxXCv6uKwTvl7mOktf8hIjP7eJp/gg1fwyA4eGgLNu7p8c7RVSwGVgQtWTOQ9I6nWt4+PPw1i+Oeb8UdV8zCM1y9iVpSqeY/D8BjlNKpAB5zX8voppQe5/5rKsEP+J3MF/62+39Y+LfnTIwalPc0/0qW7mkgygHLDtr84xIQ/vCXvuVop2ziSSqkxMnC34MJJlp7x1FjcO356lWMCN+Op1c5A7fImX2YgONrB/CIRXAYHxJWKnE53PXESbJfVA3YPc4E3Jed/3ktvZTZBwh69WRMglVb9uPPL60PHHOtYiXq+flX8fZkJMKfZdxlBZ8AJ/3zv58brp5WCyrd+r8IwBnu378C8HcAX6nwnI2HtzkaNPswATh35iG44wVH02fpivNRRSKqCG83NUhyH2wG75Vil/D2KYW3kkr4XVVe+KJlVxQ1zJ92h1uukc/cyWRwkavRzJvBdncFawwwZk8pL73v/Z89FWt3dCnrN9QKdh/4iZYQJxOpzOwzd+YEfETigQYEN4UzBsE+SXnIIS1ZdAzOS1KPO+evpmLF973TD+8AAEzuGITHvnQ6OiXlIeuBSufGgyilmwDA/X+04rgWQsgCQshzhJD3VPibFdEf3eGIMUMAAB+e6WhyoubPF3th/TEvBIbVCl4ja82aobzpcScDXvOv2NvH855K9j2V8C/YtCIvr4DZZ3+vk1LApp6Gy+fzZyaN5689y/vO9HFyryVVLqZS5DNmWX74/Q1TfsR7bRoksLnNNP9Zk0fg6HFyU2CwcLz64cnSslfLz5+Haf4GAf6dq4s8pWNQzce4ipJDkxDyKCFkieTfRQl+ZwKldAaADwO4iRAirQNHCLnSnSQWbNu2LcHpa8uYoS1Yc8OFXjF43+bvaiAG8bw12KqAaaIyH+Bqwieey2YMT+NK6o4XFP7UW/XUyu7Kv67U1TNv+tf2ylu7Me1rj7iunkJ8h+Vo/h2D84G6ybOnjMSSb52LZ699e+C8YgRxo8OE+svrdgfezwiaP5sgo4QiDWj+ajElK8NarumyElhfsGntFbq4lBT+lNKzKaVHS/7dB2ALIWQsALj/b1WcY6P7/xtwTENSVwNK6a2U0hmU0hkdHR1lXlLtyAhmH5bMKmMQnDDBSQnLVgWs7q8YC1Bt+BwvJiGgFPjvv67wNC8a0z+KN/vwG76V2PyTWqBEIRFw9axgjStzxy3alEtn4G/09xYtqRvfoHwm5NcvBnA1OqqNXJOQQD9jm+JRG/pM+Zg1eUR0zWf3IbzzmLF44LNzAPBBXtUTwnHHST1RqdnnfgCfcP/+BID7xAMIIcMJIXn371EATgXwWoW/WzanH96B0w7rwLzzp5U+OCG8EPjn6u1410+edt830JpzbjWbGFi+HtVmYLXgzT5s2f6/j69OrPkHXD3tyopos68k3X8Iaf7uifoq1PxlWU15zZ+lvyjaNnoKltIWL04ipQq5NBpM4/7KecGxZZp+yVKD+PENZsSMzPrPTZccHzlJsPxIWdMvcfnK+j3eb1WLcvfKakmlqscNAO4khFwGYB2ADwAAIWQGgKsopZcDOALATwkhNpzJ5gZKac2Ef1sug1//y8x+OTchBBmDoGjZeHKV785lGr6Zh5mExrjC/4MzyvP4SItJo/zNKN5FjZlt4nZqXrjyZp+yNH8m/BNqUyFXT9Pf8K3Er1pmWugp+IXbmUa/eut+PPTqZuV5RO+c/kg1UkuYHsFWtQyTkEDVul6hjoUMpnxkzOi01+wZZ00Sev7V1PwbkYqEP6V0B4CzJO8vAHC5+/c/AUyv5HcaiYxJQvncTcNASzbYEVtzZihHTy1429QOnNQ5HC+u2YWTOodj/lKnyLZn9okpf/nrcIK8KvD2YWafhNqUqKH7WVLT1wJ3HOjzVkpM+D/3xo6or4TMPnGLrjcKtmfqC77Pe/sYgXERcf3us3fKI6pdQ9nEnDGNkLCvpuxnexTfeNeR1fvRCmku1aMOyBgGChYNaK0Zg0hdDcvJ0dMfTOkYBAA4/bDRyBgEp0wZmdjsE/TJp973K/H2SbqSFjVrMc1u2rBCOsycs7fbef399x0jPT68Mmmu4acqopLPGtjf69j5+XKOcTR/pzyiuicwb5+sEdb8qzm2WAtrP5rj01y9rw5wNP+gpmIaJPW6tGnCp3SY0TkcRYv6RTNiimB+3L22cW8q1ZTiFhlniIM9KPzLboYStjpiGv1rm/YCAN5+hMrjOYjMTbGRUW3yD85nvZq1vCCP0vzZvTUNEpkOgpl9HM2/rGanQpzkh/WGFv4pkzGIU8mLBt9LuzRhmgxpdax/bTnTsclatlelqBx/8h8/vroib5+0IlerVUpPbG/cZH1JUxvXO7bC1De4JSMV4FF5rS49tROAc2+jqo51DG7xzlVLGz9TkhpI9mvhnzYZw686xDANUnfRmDxfPOdwXHfBEXjnMQcjnzFQKNqYepBjCrruwvhpEHgq8fO//uLpuPSUTsw5tLKCF5l+1/ydaxSFfdzJq9ZJ/dLGW+2Jmn+LvMJclLfPV86bhjevvwCZEsJ/+jgnwLKr16qpf72n+desBcnRwj9lTIOgIJh9MoZR12af1pyJK06bDNMgyGUM9Fk2LJti8qh25DPltVuW1TMuo4e04JvvPqpim3gg931KKtlnzuTiEznTBE9cjb7pNH8q1/yHKCKZSzk7sNVaoag2/w1xJ5beYo2FP/ujgVT/5up9dUDW9fbhu6vBuXrWOznTQF/Rhk2TVb8SI5V/9tQbAKrray3Cu1KmJfz5JF2q/ZC4QqjWnl5pYynce9sU2Tfj3qcomz9bdfUV0yvYUw6NqPk3V4hhHWAaxAvkYmQMwzP7TB09qBbNik2WCX+7ssRYLHK52htgcw4d5bsVcqpNpc2459OnoCVrYsd+P0lbhAdiLBolDUBcigqzjyqeIe7kF2X2YaunPstuuvvZ32jhnzJZ00DRrTfKMF03tF/9y0wcOXZIDVtXmlzGwL6eAh5ZujlUVKMR+O3lJ3t/p+nqebybnuPZ131f/nJC+r/33un4j3uc0haN5BkSB8+9V7gslVCOK6xFZYrH1/wpWrL+JLPyO+fHOnd66A3fAY9M8x8z1PFIOP2wjlD0Y73RkjW9wtjLN++rcWsqoz9cPflN2hgFm0J8WJHCuBlg0eqHCx5iKiEfN8KZaf6/5yZ2BttcL1g2Wrj9qf6sVSzDN/s0jvTXwj9lMqZTbJrX6gblG2eBNaxV7pnRiJj9sOHLCzI+DKE/auI2GhcdNw5rbrgQo93UJQyl5h/T2+mIg53V8rC2XOgzz+xTtPutQlkcZOVP6x0t/FMmY5CQ2aeRGNbWPMKf1yzTMrEE7dT+M/7qhY0T1l9t+Fv228t87T2uzf8H7z8Gf/7UbG8FzXPCxGE49pBhZbskp4Xn51/TViRDC/+UybhmnxI1quuWoRLtqlExJeUEKz6nITf7JPHZnzvzkIbx/kqTL51zGOZM9WM34tr823IZnDhxhNQBoS2XwX2fOVVZFKZaXP62yegYnMdZRxxU03YkoXHsEQ1CxiToKdiRyajqmVGDfOF/2ZxJNWxJ5WRS3PD1z+nrS8GCI/HPf/3Fx+D6i+X5f5oRlUkkqatrNWvyJuWwgwbjxevOrnUzElHHt7MxyRiOzZ+5vX3nPUfXuEXJmMn5sV9TJ4WmyyWw4ZtSTw/Y/Ln3my1JWzVI6ppZzZq8AwGt+acMy+dvU4rRg/P46KyJtW5SInghliQCVTYuzz96TBpNKhteWPSHzT9g9tE+5kq8jJfCM0hazyDOZPG3L5xW043fRkIL/5Rh+fydSk+N3QmTtF+2v33cIfLC5dXCMAgMwvL5p+/t08K5E2rhn5yk4yPOI5xah4Xt6xUt/FMmYxjYeaAPdy5YX+um1Jx6mPwyhpOrKK0cavzG7vcu9msU1cO11isqx7ekE6Y2+6SLNlSmTMYk2Lqvt9bNqAvqQRtmQnl4ezpeTEwAjWzPYdQgP2Cv2aJ100SV7jipeUaXZUwXrfmnzEDVAGXj0qyDTVAWHcoL6jRQCfsTJtTW1FXPVBr9ahgE08YMxlWnTyl9sKYkWvinTLbJinJXQj1o/szrqiMl4c8sGLJLe+rLZ2JESiuMpiLFeMdHPn9aeicb4GjhnzJxQ9YHAvW0CmLVyiplZHsOx44fii++I+wGe8iItlR+o1nRVpv6Qgv/lGmGuqxfOW8aVmzem+g7c2dOwKPLtmDx+j3ee/Wg+TPKLUojkjEN3Hf1nFTONVBozEQnzY8W/ikTVZquUfjUGcltqh2D87j/6jk46uuPeFlB60nzz1c5y6PGh0VC109v0ADa2yd1sgPc7HMiFyHc5U4C9UC1U/xqfBox4+VAQI+IlKknbbcW3HTJcd7fm/f01LAlQdIy+2jKp5Fy3Q8EtNknZQZ6jhfe2+XQOipZmc8O7OdSS0Sb/y8+eRJWbWnsQkHNQEUjghDyAULIUkKITQiZEXHceYSQFYSQ1YSQeZX8Zr1TT5uctaaeCpxom3/tYWafMw8fjStP0776tabSEbEEwMUAnlQdQAgxAdwM4HwARwKYSwhp2soXSfK6Nzv1FPWqzT614yi3Elc9rQQ1FZp9KKXLgJKDfCaA1ZTSN9xj/wDgIgCvVfLb9YrW/OsTrfnXjvcePw7HjB+mhX+dUY0RMQ7AW9zr9e57TUnSNLWa6qBt/rWDEKIFfx1SUvMnhDwKQJaY/TpK6X0xfkOmCkvjPgghVwK4EgAmTJgQ49T1hzb71BcPfHYOlm7cg7ac9m3QaHhKjghKaaW1ydYDOIR7PR7ARsVv3QrgVgCYMWNGQwYGas2/vjh63NCa13fVaOqRakiqFwFMJYRMIoTkAHwIwP1V+N2aoG3+Go2mEajU1fO9hJD1AGYDeJAQMt99/2BCyEMAQCktArgawHwAywDcSSldWlmz6xdt9tFoNI1Apd4+9wC4R/L+RgAXcK8fAvBQJb/VKAz0CF+NRtMYaAN1yiQpeq7RaDS1QrtApAyv+X/opEMijmxe2nMmOke117oZGo0mAi38U4Zl9Rw/vBU3vO+YGremNiz99nm1boJGoymBtlGkDMvnX0eZDTQajSaEFv4pwyp56fS1Go2mntHCP2WYzV9r/hqNpp7Rwj9lWD5/Q0t/jUZTx2jhnzIZz+yj0Wg09YsW/inDIny14q/RaOoZLfxTJuN5+2jpr9Fo6hct/FOGyXwt+jUaTT2jhX/KUDcRtVb8NRpNPaOFf8pQt06N9vbRaDT1jBb+KcOCu1pzumC4RqOpX3Run5Q57KBB+NxZU3HJAE3qptFoGgMt/FOGEIIvnHNYrZuh0Wg0kWizj0aj0QxAtPDXaDSaAYgW/hqNRjMA0cJfo9FoBiBa+Gs0Gs0ARAt/jUajGYBo4a/RaDQDEC38NRqNZgBCKMtEVmcQQrYBWFvBKUYB2J5ScxoFfc3Nz0C7XkBfc1ImUko7Sh1Ut8K/UgghCyilM2rdjmqir7n5GWjXC+hr7i+02Uej0WgGIFr4azQazQCkmYX/rbVuQA3Q19z8DLTrBfQ19wtNa/PXaDQajZpm1vw1Go1Go6DphD8h5DxCyApCyGpCyLxatyctCCGHEEKeIIQsI4QsJYR8zn1/BCHkb4SQVe7/w933CSHkx+59WEwIOaG2V1A+hBCTEPIyIeQB9/UkQsjz7jX/kRCSc9/Pu69Xu5931rLd5UIIGUYIuYsQstx93rOb/TkTQr7g9uslhJA7CCEtzfacCSG3E0K2EkKWcO8lfq6EkE+4x68ihHyi3PY0lfAnhJgAbgZwPoAjAcwlhBxZ21alRhHAlyilRwCYBeAz7rXNA/AYpXQqgMfc14BzD6a6/64EcEv1m5wanwOwjHv9XwB+5F7zLgCXue9fBmAXpfRQAD9yj2tE/gfAI5TSaQCOhXPtTfucCSHjAPwbgBmU0qMBmAA+hOZ7zr8EcJ7wXqLnSggZAeAbAE4GMBPAN9iEkRhKadP8AzAbwHzu9bUArq11u/rpWu8DcA6AFQDGuu+NBbDC/funAOZyx3vHNdI/AOPdQfF2AA8AIHCCXzLiMwcwH8Bs9++Mexyp9TUkvN4hAN4U293MzxnAOABvARjhPrcHAJzbjM8ZQCeAJeU+VwBzAfyUez9wXJJ/TaX5w+9EjPXue02Fu8w9HsDzAA6ilG4CAPf/0e5hzXIvbgLwZQC2+3okgN2U0qL7mr8u75rdz/e4xzcSkwFsA/AL19T1c0JIO5r4OVNKNwC4EcA6AJvgPLeFaO7nzEj6XFN73s0m/InkvaZyZyKEDALwZwCfp5TujTpU8l5D3QtCyDsBbKWULuTflhxKY3zWKGQAnADgFkrp8QAOwDcFyGj4a3bNFhcBmATgYADtcMweIs30nEuhusbUrr3ZhP96AIdwr8cD2FijtqQOISQLR/D/jlJ6t/v2FkLIWPfzsQC2uu83w704FcC7CSFrAPwBjunnJgDDCCEZ9xj+urxrdj8fCmBnNRucAusBrKeUPu++vgvOZNDMz/lsAG9SSrdRSgsA7gZwCpr7OTOSPtfUnnezCf8XAUx1vQRycDaN7q9xm1KBEEIA3AZgGaX0h9xH9wNgO/6fgLMXwN7/uOs1MAvAHra8bBQopddSSsdTSjvhPMvHKaUfAfAEgPe7h4nXzO7F+93jG0ojpJRuBvAWIeRw962zALyGJn7OcMw9swghbW4/Z9fctM+ZI+lznQ/gHYSQ4e6K6R3ue8mp9QZIP2yoXABgJYDXAVxX6/akeF1z4CzvFgNY5P67AI6t8zEAq9z/R7jHEzieT68DeBWOJ0XNr6OC6z8DwAPu35MBvABgNYA/Aci777e4r1e7n0+udbvLvNbjACxwn/W9AIY3+3MG8C0AywEsAfAbAPlme84A7oCzp1GAo8FfVs5zBfAv7rWvBvDJctujI3w1Go1mANJsZh+NRqPRxEALf41GoxmAaOGv0Wg0AxAt/DUajWYAooW/RqPRDEC08NdoNJoBiBb+Go1GMwDRwl+j0WgGIP8f60tNiFtaRqsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation Started at:\n",
      "2019-10-23 16:21:58.679894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/at-lab/anaconda3/envs/Python3.7/lib/python3.7/site-packages/ipykernel_launcher.py:305: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "40\n",
      "80\n",
      "120\n",
      "160\n",
      "200\n",
      "240\n",
      "280\n",
      "320\n",
      "360\n",
      "400\n",
      "440\n",
      "480\n",
      "520\n",
      "560\n",
      "600\n",
      "640\n",
      "680\n",
      "720\n",
      "760\n",
      "800\n",
      "840\n",
      "880\n",
      "920\n",
      "960\n",
      "1000\n",
      "1040\n",
      "1080\n",
      "1120\n",
      "1160\n",
      "1200\n",
      "1240\n",
      "1280\n",
      "1320\n",
      "1360\n",
      "1400\n",
      "1440\n",
      "1480\n",
      "1520\n",
      "1560\n",
      "1600\n",
      "1640\n",
      "1680\n",
      "1720\n",
      "1760\n",
      "1800\n",
      "1840\n",
      "1880\n",
      "1920\n",
      "1960\n",
      "2000\n",
      "2040\n",
      "2080\n",
      "2120\n",
      "2160\n",
      "2200\n",
      "2240\n",
      "2280\n",
      "2320\n",
      "2360\n",
      "2400\n",
      "2440\n",
      "2480\n",
      "\n",
      " \n",
      "Completed episodes\n",
      "Simulation Ended at:\n",
      "2019-10-24 13:49:40.410093\n"
     ]
    }
   ],
   "source": [
    "################# Buffer #################\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import psutil\n",
    "import gc\n",
    "from random import randrange, uniform\n",
    "\n",
    "import datetime\n",
    "\n",
    "#from __future__ import division\n",
    "#import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#import numpy as np\n",
    "#import torch\n",
    "import shutil\n",
    "#import torch.autograd as Variable\n",
    "\n",
    "import random\n",
    "from random import randrange, uniform\n",
    "\n",
    "import scipy.integrate as integrate\n",
    "from scipy.integrate import quad\n",
    "from math import pow\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "#import numpy as np\n",
    "\n",
    "class MemoryBuffer:\n",
    "\n",
    "    def __init__(self, size):\n",
    "                    self.buffer = deque(maxlen=size)\n",
    "                    self.maxSize = size\n",
    "                    self.len = 0\n",
    "\n",
    "    def sample(self, count = 100):\n",
    "        \n",
    "        \"\"\"\n",
    "        samples a random batch from the replay memory buffer\n",
    "        :param count: batch size\n",
    "        :return: batch (numpy array)\n",
    "        \"\"\"\n",
    "        batch = []\n",
    "        count = min(count, self.len)\n",
    "        batch = random.sample(self.buffer, count)\n",
    "\n",
    "        s_arr = np.array([arr[0] for arr in batch])\n",
    "        a_arr = np.array([arr[1] for arr in batch])\n",
    "        #print('\\nbatch in sampling',batch)#np.float32\n",
    "        r_arr = np.array([arr[2] for arr in batch])\n",
    "        s1_arr = np.array([arr[3] for arr in batch])\n",
    "        return s_arr, a_arr, r_arr, s1_arr\n",
    "\n",
    "    def len(self):\n",
    "        return self.len\n",
    "\n",
    "    def add(self, s, a, r, s1):\n",
    "        \"\"\"\n",
    "        adds a particular transaction in the memory buffer\n",
    "        :param s: current state\n",
    "        :param a: action taken\n",
    "        :param r: reward received\n",
    "        :param s1: next state\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        transition = (s,a,r,s1)\n",
    "        self.len += 1\n",
    "        if self.len > self.maxSize:\n",
    "            self.len = self.maxSize\n",
    "        self.buffer.append(transition)\n",
    "        \n",
    "\n",
    "############## Actor Critic Model ###############\n",
    "\n",
    "\n",
    "\n",
    "EPS = 0.003\n",
    "\n",
    "def fanin_init(size, fanin=None):\n",
    "\tfanin = fanin or size[0]\n",
    "\tv = 1. / np.sqrt(fanin)\n",
    "\treturn torch.Tensor(size).uniform_(-v, v)\n",
    "\n",
    "class Critic(nn.Module):\n",
    "\n",
    "\tdef __init__(self, state_dim, action_dim):\n",
    "\t\t\"\"\"\n",
    "\t\t:param state_dim: Dimension of input state (int)\n",
    "\t\t:param action_dim: Dimension of input action (int)\n",
    "\t\t:return:\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(Critic, self).__init__()\n",
    "\n",
    "\t\tself.state_dim = state_dim\n",
    "\t\tself.action_dim = action_dim\n",
    "\n",
    "\t\tself.fcs1 = nn.Linear(state_dim,7)\n",
    "\t\tself.fcs1.weight.data = fanin_init(self.fcs1.weight.data.size())\n",
    "\t\t#self.fcs1_bn = nn.BatchNorm1d(10)  \n",
    "        \n",
    "\t\tself.fcs2 = nn.Linear(7,12)\n",
    "\t\tself.fcs2.weight.data = fanin_init(self.fcs2.weight.data.size())\n",
    "\t\t#self.fcs2_bn = nn.BatchNorm1d(16)\n",
    "        \n",
    "\t\tself.fca1 = nn.Linear(action_dim,12)\n",
    "\t\tself.fca1.weight.data = fanin_init(self.fca1.weight.data.size())\n",
    "\t\t#self.fca1_bn = nn.BatchNorm1d(16)\n",
    "        \n",
    "\t\tself.fc2 = nn.Linear(24,8)\n",
    "\t\tself.fc2.weight.data = fanin_init(self.fc2.weight.data.size())\n",
    "\t\t#self.fc2_bn = nn.BatchNorm1d(16)\n",
    "        \n",
    "\t\tself.fc3 = nn.Linear(8,1)\n",
    "\t\tself.fc3.weight.data.uniform_(-EPS,EPS)\n",
    "\n",
    "\tdef forward(self, state, action):\n",
    "\t\t\"\"\"\n",
    "\t\treturns Value function Q(s,a) obtained from critic network\n",
    "\t\t:param state: Input state (Torch Variable : [n,state_dim] )\n",
    "\t\t:param action: Input Action (Torch Variable : [n,action_dim] )\n",
    "\t\t:return: Value function : Q(S,a) (Torch Variable : [n,1] )\n",
    "\t\t\"\"\"\n",
    "\t\t##print(\"\\nsstate in before fwd\",state.size(),\"action in before fwd\",action.size())\n",
    "\t\ts1 = F.relu(self.fcs1(state))\n",
    "\t\ts2 = F.relu(self.fcs2(s1))\n",
    "\t\ta1 = F.relu(self.fca1(action))\n",
    "\t\t#print(\"\\ns2 in fwd\",s2.size(),\"a1 in fwd\",a1.size())\n",
    "\t\tx = torch.cat((s2,a1),dim=1)\n",
    "\t\t#print('\\nx after cat',x.size())\n",
    "\t\tx = F.relu(self.fc2(x))\n",
    "\t\tx = self.fc3(x)\n",
    "\t\t#x = (x - min_action)/(max_action - min_action)\n",
    "\t\t#print('\\nQ value', x)\n",
    "\t\treturn x\n",
    "\n",
    "\n",
    "class Actor(nn.Module):\n",
    "\n",
    "\tdef __init__(self, state_dim, action_dim): #, action_lim\n",
    "\t\t\"\"\"\n",
    "\t\t:param state_dim: Dimension of input state (int)\n",
    "\t\t:param action_dim: Dimension of output action (int)\n",
    "\t\t:param action_lim: Used to limit action in [-action_lim,action_lim]\n",
    "\t\t:return:\n",
    "\t\t\"\"\"\n",
    "\t\tsuper(Actor, self).__init__()\n",
    "\n",
    "\t\tself.state_dim = state_dim\n",
    "\t\tself.action_dim = action_dim\n",
    "\t\t#self.action_lim = action_lim\n",
    "\n",
    "\t\tself.fc1 = nn.Linear(state_dim,7)\n",
    "\t\tself.fc1.weight.data = fanin_init(self.fc1.weight.data.size())\n",
    "\t\t#self.fc1_bn = nn.BatchNorm1d(10)\n",
    "\t\tself.fc2 = nn.Linear(7,12)\n",
    "\t\tself.fc2.weight.data = fanin_init(self.fc2.weight.data.size())\n",
    "\t\t#self.fc2_bn = nn.BatchNorm1d(16)\n",
    "\t\tself.fc3 = nn.Linear(12,5)\n",
    "\t\tself.fc3.weight.data = fanin_init(self.fc3.weight.data.size())\n",
    "\t\t#self.fc3_bn = nn.BatchNorm1d(6)\n",
    "\t\tself.fc4 = nn.Linear(5,action_dim)\n",
    "\t\tself.fc4.weight.data.uniform_(-EPS,EPS)\n",
    "\t\t\n",
    "        \n",
    "\tdef forward(self, state):\n",
    "\t\t\"\"\"\n",
    "\t\treturns policy function Pi(s) obtained from actor network\n",
    "\t\tthis function is a gaussian prob distribution for all actions\n",
    "\t\twith mean lying in (-1,1) and sigma lying in (0,1)\n",
    "\t\tThe sampled action can , then later be rescaled\n",
    "\t\t:param state: Input state (Torch Variable : [n,state_dim] )\n",
    "\t\t:return: Output action (Torch Variable: [n,action_dim] )\n",
    "\t\t\"\"\"\n",
    "\t\t#x = state\n",
    "\t\tx = F.relu(self.fc1(state))\n",
    "\t\tx = F.relu(self.fc2(x))\n",
    "\t\tx = F.relu(self.fc3(x))\n",
    "\t\t#x = F.relu(self.fc1(state))        \n",
    "\t\t#x = F.relu(self.fc2(self.fc1_bn(x)))\n",
    "\t\t#x = F.relu(self.fc3(self.fc2_bn(x)))\n",
    "\t\taction = F.relu(self.fc4(x))\n",
    "\t\tm = nn.Sigmoid()\n",
    "\t\taction = m(action)\n",
    "\t\t#action = action * self.action_lim\n",
    "\n",
    "\t\treturn action\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "############ Train ###########\n",
    "\n",
    "\n",
    "\n",
    "#import utils\n",
    "#import model\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.002\n",
    "GAMMA = 0.99\n",
    "TAU = 0.001\n",
    "#Loss_Critic = []\n",
    "#Loss_Actor = []\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "\tdef __init__(self, state_dim, action_dim, ram): #, self.action_lim\n",
    "\t\t\"\"\"\n",
    "\t\t:param state_dim: Dimensions of state (int)\n",
    "\t\t:param action_dim: Dimension of action (int)\n",
    "\t\t:param action_lim: Used to limit action in [-action_lim,action_lim]\n",
    "\t\t:param ram: replay memory buffer object\n",
    "\t\t:return:\n",
    "\t\t\"\"\"\n",
    "\t\tself.state_dim = state_dim\n",
    "\t\tself.action_dim = action_dim\n",
    "\t\t#self.action_lim = action_lim\n",
    "\t\tself.ram = ram\n",
    "\t\tself.iter = 0\n",
    "\t\tself.noise = OrnsteinUhlenbeckActionNoise(self.action_dim)\n",
    "\n",
    "\t\tself.actor = Actor(self.state_dim, self.action_dim) # , self.action_lim\n",
    "\t\tself.target_actor = Actor(self.state_dim, self.action_dim) #, self.action_lim\n",
    "\t\tself.actor_optimizer = torch.optim.Adam(self.actor.parameters(),LEARNING_RATE)\n",
    "\n",
    "\t\tself.critic = Critic(self.state_dim, self.action_dim)\n",
    "\t\tself.target_critic = Critic(self.state_dim, self.action_dim)\n",
    "\t\tself.critic_optimizer = torch.optim.Adam(self.critic.parameters(),LEARNING_RATE)\n",
    "\n",
    "\t\thard_update(self.target_actor, self.actor)\n",
    "\t\thard_update(self.target_critic, self.critic)\n",
    "\t\t\n",
    "        \n",
    "\tdef get_exploitation_action(self, state):\n",
    "\t\t\"\"\"\n",
    "\t\tgets the action from target actor added with exploration noise\n",
    "\t\t:param state: state (Numpy array)\n",
    "\t\t:return: sampled action (Numpy array)\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\taction = self.target_actor.forward(state).detach()\n",
    "\t\t#print('\\nExploitation action',action)\n",
    "\t\treturn action.data.numpy()\n",
    "\n",
    "\t\t        \n",
    "\t\t        \n",
    "\tdef get_exploration_action(self, state):\n",
    "\t\t\"\"\"\n",
    "\t\tgets the action from actor added with exploration noise\n",
    "\t\t:param state: state (Numpy array)\n",
    "\t\t:return: sampled action (Numpy array)\n",
    "\t\t\"\"\"\n",
    "\t\t#state = [state_0, state_1, state_2, state_3, state_4]\n",
    "\t\taction = self.actor.forward(state).detach()\n",
    "\t\t#print(action)        \n",
    "\t\tnew_action = action.data.numpy() + (self.noise.sample()) # * self.action_lim)  \n",
    "\t\t#print('\\nExploration action', new_action)        \n",
    "\t\treturn new_action\n",
    "\n",
    "\tdef optimize(self):\n",
    "\t\t\"\"\"\n",
    "\t\tSamples a random batch from replay memory and performs optimization\n",
    "\t\t:return:\n",
    "\t\t\"\"\"\n",
    "\t\t#global loss_critic, loss_actor\n",
    "        \n",
    "\t\ts1,a1,r1,s2 = self.ram.sample(BATCH_SIZE)\n",
    "\t\t#print('\\ns1 in optim',s1.shape(),'a1 in optim',a1.shape())\n",
    "\n",
    "\t\ts1 = torch.from_numpy(s1).float() #s1 = torch.Tensor(s1).float() #Variable(torch.from_numpy(s1))\n",
    "\t\ta1 = torch.from_numpy(a1).float() #a1 = torch.Tensor(a1).float()\n",
    "\t\tr1 = torch.from_numpy(r1).float() #r1 = torch.Tensor(r1).float()\n",
    "\t\ts2 = torch.from_numpy(s2).float() #s2 = torch.Tensor(s2).float()\n",
    "\t\t#print('\\ns1 in optim after conv',s1.size(),'a1 in optim after conv',a1.size())\n",
    "\n",
    "\t\t# ---------------------- optimize critic ----------------------\n",
    "\t\t# Use target actor exploitation policy here for loss evaluation\n",
    "\t\t#print('s2 before trg actor fwd',s2)        \n",
    "\t\ta2 = self.target_actor.forward(s2).detach()\n",
    "\t\tnext_val = torch.squeeze(self.target_critic.forward(s2, a2).detach())\n",
    "\t\t# y_exp = r + gamma*Q'( s2, pi'(s2))\n",
    "\t\ty_expected = r1 + GAMMA*next_val\n",
    "\t\t# y_pred = Q( s1, a1)\n",
    "        \n",
    "\t\t#print('\\naction shape problem', a1)        \n",
    "\t\ty_predicted = torch.squeeze(self.critic.forward(s1, a1))\n",
    "\t\t#print('\\nforward done')        \n",
    "\t\t# compute critic loss, and update the critic\n",
    "\t\tloss_critic = F.smooth_l1_loss(y_predicted, y_expected)\n",
    "\t\t#print('\\n Critic Loss ', loss_critic)\n",
    "\t\t#Loss_Critic.append(loss_critic)\n",
    "\t\t#torch.save(Loss_Critic, 'Loss_Critic.pt')\n",
    "\n",
    "\t\tself.critic_optimizer.zero_grad()\n",
    "\t\tloss_critic.backward()\n",
    "\t\tself.critic_optimizer.step()\n",
    "\n",
    "\t\t# ---------------------- optimize actor ----------------------\n",
    "\t\tpred_a1 = self.actor.forward(s1)\n",
    "\t\tloss_actor = -1 * torch.sum(self.critic.forward(s1, pred_a1))\n",
    "\t\t#Loss_Actor.append(loss_actor)\n",
    "\t\t#torch.save(Loss_Actor, 'Loss_Actor.pt')\n",
    "\n",
    "\n",
    "\n",
    "\t\t#print(loss_actor)        \n",
    "\t\tself.actor_optimizer.zero_grad()\n",
    "\t\tloss_actor.backward()\n",
    "\t\tself.actor_optimizer.step()\n",
    "\n",
    "\t\tsoft_update(self.target_actor, self.actor, TAU)\n",
    "\t\tsoft_update(self.target_critic, self.critic, TAU)\n",
    "\n",
    "\t\t# if self.iter % 100 == 0:\n",
    "\t\t# \tprint 'Iteration :- ', self.iter, ' Loss_actor :- ', loss_actor.data.numpy(),\\\n",
    "\t\t# \t\t' Loss_critic :- ', loss_critic.data.numpy()\n",
    "\t\t# self.iter += 1\n",
    "\t#def losses(loss_actor, loss_critic):\n",
    "\t\t#A = loss_actor\n",
    "\t\t#B = loss_critic\n",
    "\t\t#return A, B\n",
    "    #C,D = \n",
    "\tdef save_models(self, episode_count, path_target, path_critic):\n",
    "\t\t\"\"\"\n",
    "\t\tsaves the target actor and critic models\n",
    "\t\t:param episode_count: the count of episodes iterated\n",
    "\t\t:return:\n",
    "\t\t\"\"\"\n",
    "\t\t        \n",
    "\t\ttorch.save(self.target_actor.state_dict(),  path_target )#, 'C:\\Users\\hp\\Desktop\\Python DDPG') #'./Models/' + str(episode_count) + '_actor.pt'\n",
    "\t\ttorch.save(self.target_critic.state_dict(), path_critic)#, 'C:\\Users\\hp\\Desktop\\Python DDPG') #'./Models/' + str(episode_count) + '_critic.pt'\n",
    "\t\t#print ('Models saved successfully')\n",
    "\t\t#retrn\n",
    "\tdef load_models(self, episode):\n",
    "\t\t\"\"\"\n",
    "\t\tloads the target actor and critic models, and copies them onto actor and critic models\n",
    "\t\t:param episode: the count of episodes iterated (used to find the file name)\n",
    "\t\t:return:\n",
    "\t\t\"\"\"\n",
    "\t\tself.actor.load_state_dict(torch.load('./Models/' + str(episode) + '_actor.pt'))\n",
    "\t\tself.critic.load_state_dict(torch.load('./Models/' + str(episode) + '_critic.pt'))\n",
    "\t\thard_update(self.target_actor, self.actor)\n",
    "\t\thard_update(self.target_critic, self.critic)\n",
    "\t\t#print('Models loaded succesfully')\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "################# Utils #################\n",
    "\n",
    "\n",
    "\n",
    "def soft_update(target, source, tau):\n",
    "\t\"\"\"\n",
    "\tCopies the parameters from source network (x) to target network (y) using the below update\n",
    "\ty = TAU*x + (1 - TAU)*y\n",
    "\t:param target: Target network (PyTorch)\n",
    "\t:param source: Source network (PyTorch)\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "\tfor target_param, param in zip(target.parameters(), source.parameters()):\n",
    "\t\ttarget_param.data.copy_(\n",
    "\t\t\ttarget_param.data * (1.0 - tau) + param.data * tau\n",
    "\t\t)\n",
    "\n",
    "\n",
    "def hard_update(target, source):\n",
    "\t\"\"\"\n",
    "\tCopies the parameters from source network to target network\n",
    "\t:param target: Target network (PyTorch)\n",
    "\t:param source: Source network (PyTorch)\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "\tfor target_param, param in zip(target.parameters(), source.parameters()):\n",
    "\t\t\ttarget_param.data.copy_(param.data)\n",
    "\n",
    "\n",
    "def save_training_checkpoint(state, is_best, episode_count):\n",
    "\t\"\"\"\n",
    "\tSaves the models, with all training parameters intact\n",
    "\t:param state:\n",
    "\t:param is_best:\n",
    "\t:param filename:\n",
    "\t:return:\n",
    "\t\"\"\"\n",
    "\tfilename = str(episode_count) + 'checkpoint.path.rar'\n",
    "\ttorch.save(state, filename)\n",
    "\tif is_best:\n",
    "\t\tshutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "# Based on http://math.stackexchange.com/questions/1287634/implementing-ornstein-uhlenbeck-in-matlab\n",
    "class OrnsteinUhlenbeckActionNoise:\n",
    "\n",
    "\tdef __init__(self, action_dim, mu = 0, theta = 0.15, sigma = 0.2):\n",
    "\t\tself.action_dim = action_dim\n",
    "\t\tself.mu = mu\n",
    "\t\tself.theta = theta\n",
    "\t\tself.sigma = sigma\n",
    "\t\tself.X = np.ones(self.action_dim) * self.mu\n",
    "\n",
    "\tdef reset(self):\n",
    "\t\tself.X = np.ones(self.action_dim) * self.mu\n",
    "\n",
    "\tdef sample(self):\n",
    "\t\tdx = self.theta * (self.mu - self.X)\n",
    "\t\tdx = dx + self.sigma * np.random.randn(len(self.X))\n",
    "\t\tself.X = self.X + dx\n",
    "\t\treturn self.X\n",
    "\n",
    "\n",
    "# use this to plot Ornstein Uhlenbeck random motion\n",
    "if __name__ == '__main__':\n",
    "\tou = OrnsteinUhlenbeckActionNoise(1)\n",
    "\tstates = []\n",
    "\tfor i in range(1000):\n",
    "\t\tstates.append(ou.sample())\n",
    "\n",
    "\n",
    "\tplt.plot(states)\n",
    "\tplt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "################################### ENVIRONMENT ############################################\n",
    "\n",
    "\n",
    "# Variable Declaration before \n",
    "Silo_Filllevel_1 = 11.6133\n",
    "Silo_Filllevel_2 = 11.6133\n",
    "Silo_Filllevel_3 = 11.6133\n",
    "\n",
    "Hopper_Filllevel_1 = 4.55\n",
    "Hopper_Filllevel_2 = 0\n",
    "Hopper_Filllevel_3 = 0\n",
    "\n",
    "if Silo_Filllevel_1 >= 1:\n",
    "    Silo_Empty_1 = 1\n",
    "else:\n",
    "    Silo_Empty_1 = 0\n",
    "            \n",
    "if Silo_Filllevel_2 >= 1:\n",
    "    Silo_Empty_2 = 1\n",
    "else:\n",
    "    Silo_Empty_2 = 0\n",
    "          \n",
    "if Silo_Filllevel_3 >= 1:\n",
    "    Silo_Empty_3 = 1\n",
    "else:\n",
    "    Silo_Empty_3 = 0\n",
    "    \n",
    "if Hopper_Filllevel_1 >= 1:\n",
    "    Hopper_Empty_1 = 1\n",
    "else:\n",
    "    Hopper_Empty_1 = 0\n",
    "            \n",
    "if Hopper_Filllevel_2 >= 1:\n",
    "    Hopper_Empty_2 = 1\n",
    "else:\n",
    "    Hopper_Empty_2 = 0\n",
    "            \n",
    "if Hopper_Filllevel_3 >= 1:\n",
    "    Hopper_Empty_3 = 1\n",
    "else:\n",
    "    Hopper_Empty_3 = 0\n",
    "\n",
    "VP_Prev_2 = 0\n",
    "VP_Prev_3 = 0\n",
    "\n",
    "Rising_2 = 0\n",
    "Falling_2 = 0\n",
    "Rising_3 = 0\n",
    "Falling_3 = 0\n",
    "\n",
    "Q_Flip_2 = 0\n",
    "Q_Flip_3 = 0\n",
    "\n",
    "Q_Flip_Prev_2 = 0\n",
    "Q_Flip_Prev_3 = 0\n",
    "\n",
    "Saturator_2 = 0\n",
    "Saturator_3 = 0\n",
    "\n",
    "MF_S_H_1 = 0\n",
    "MF_S_H_2 = 0\n",
    "MF_S_H_3 = 0\n",
    "\n",
    "MF_VC_2 = 0\n",
    "MF_VC_3 = 0\n",
    "\n",
    "Energy_Conveyor_Sim = 0\n",
    "Energy_VC_2_Sim = 0\n",
    "Energy_Vibration_Belt_Sim = 0\n",
    "Energy_VC_3_Sim = 0\n",
    "Energy_Rotary_Air_Lock_Sim = 0\n",
    "\n",
    "Silo_Fill_1_Error = []\n",
    "Time = []\n",
    "###########\n",
    "Conveyor_Motor_Speed = 0\n",
    "Vibration_Belt_Start = 1\n",
    "Dosing_Speed = 600\n",
    "Demand = 50\n",
    "\n",
    "VP_2 = 0\n",
    "VP_3 = 1\n",
    "\n",
    "VP_Time_2 = 10\n",
    "VP_Time_3 = 10\n",
    "\n",
    "Exchanged_Mass_Sim = 0\n",
    "Exchanged_Mass_Sim_Prev = 0\n",
    "reward_1 = 0\n",
    "reward_2 = 0\n",
    "reward_3 = 0\n",
    "reward_4 = 0\n",
    "reward_5 = 0\n",
    "\n",
    "Total_Reward_1 = 0\n",
    "Total_Reward_2 = 0\n",
    "Total_Reward_3 = 0\n",
    "Total_Reward_4 = 0\n",
    "Total_Reward_5 = 0\n",
    "Total_Reward_6 = 0\n",
    "\n",
    "\n",
    "\n",
    "#################### Initial State for an episode ###################\n",
    "\n",
    "\n",
    "#if action_counter == 1:\n",
    "def initial_state():\n",
    "    \n",
    "    global Silo_Filllevel_1, Silo_Filllevel_2, Silo_Filllevel_3, Hopper_Filllevel_1, Hopper_Filllevel_2, Hopper_Filllevel_3\n",
    "    global Silo_Empty_1, Hopper_Empty_1, Q_Flip_2, Q_Flip_3, Q_Flip_Prev_2, Q_Flip_Prev_3, Saturator_2, Saturator_3\n",
    "    global VP_Prev_2, VP_Prev_3\n",
    "    \n",
    "    Silo_Filllevel_1 = uniform(0,11.42)\n",
    "    Silo_Filllevel_2 = uniform(0,11.42)\n",
    "    Silo_Filllevel_3 = uniform(0,11.42)\n",
    "    \n",
    "    Hopper_Filllevel_1 = uniform(0,9.1)\n",
    "    Hopper_Filllevel_2 = uniform(0,9.1)\n",
    "    Hopper_Filllevel_3 = uniform(0,9.1)\n",
    "    \n",
    "    if Silo_Filllevel_1 >= 1:\n",
    "        Silo_Empty_1 = 1\n",
    "    else:\n",
    "        Silo_Empty_1 = 0\n",
    "            \n",
    "    if Silo_Filllevel_2 >= 1:\n",
    "        Silo_Empty_2 = 1\n",
    "    else:\n",
    "        Silo_Empty_2 = 0\n",
    "          \n",
    "    if Silo_Filllevel_3 >= 1:\n",
    "        Silo_Empty_3 = 1\n",
    "    else:\n",
    "        Silo_Empty_3 = 0\n",
    "    \n",
    "    if Hopper_Filllevel_1 >= 1:\n",
    "        Hopper_Empty_1 = 1\n",
    "    else:\n",
    "        Hopper_Empty_1 = 0\n",
    "            \n",
    "    if Hopper_Filllevel_2 >= 1:\n",
    "        Hopper_Empty_2 = 1\n",
    "    else:\n",
    "        Hopper_Empty_2 = 0\n",
    "            \n",
    "    if Hopper_Filllevel_3 >= 1:\n",
    "        Hopper_Empty_3 = 1\n",
    "    else:\n",
    "        Hopper_Empty_3 = 0\n",
    "    \n",
    "    VP_Prev_2 = randrange(0,2)\n",
    "    VP_Prev_3 = randrange(0,2)\n",
    "\n",
    "    Rising_2 = randrange(0,2)\n",
    "    Falling_2 = randrange(0,2)\n",
    "    Rising_3 = randrange(0,2)\n",
    "    Falling_3 = randrange(0,2)\n",
    "\n",
    "    Q_Flip_2 = randrange(0,2)\n",
    "    Q_Flip_3 = randrange(0,2)\n",
    "\n",
    "    Q_Flip_Prev_2 = randrange(0,2)\n",
    "    Q_Flip_Prev_3 = randrange(0,2)\n",
    "\n",
    "    Saturator_2 = randrange(0,2)\n",
    "    Saturator_3 = randrange(0,2)\n",
    "    \n",
    "    \n",
    "\n",
    "############### State Space Reset ################\n",
    "\n",
    "def state_space_reset():\n",
    "    global Energy_Conveyor_Sim, Energy_Vibration_Belt_Sim, Energy_VC_2_Sim, Energy_VC_3_Sim, Energy_Rotary_Air_Lock_Sim\n",
    "    global reward_1, reward_2, reward_3, Total_Reward_1, Total_Reward_2, Total_Reward_3, Demand, Total_Energy_Sim, Exchanged_Mass_Sim, Total_Energy_Sim_Prev, reached\n",
    "    global sum_of_actor_loss_1, sum_of_critic_loss_1,sum_of_actor_loss_2, sum_of_critic_loss_2,sum_of_actor_loss_3, sum_of_critic_loss_3,sum_of_actor_loss_4, sum_of_critic_loss_4,sum_of_actor_loss_5, sum_of_critic_loss_5\n",
    "    global Total_Reward_4, Total_Reward_5, Total_Reward_6, Exchanged_Mass_Sim_Prev\n",
    "    Exchanged_Mass_Sim = 0\n",
    "    Total_Energy_Sim_Prev = 0\n",
    "    Exchanged_Mass_Sim_Prev = 0\n",
    "    Energy_Conveyor_Sim = 0                \n",
    "    Energy_VC_2_Sim = 0\n",
    "    Energy_Vibration_Belt_Sim = 0\n",
    "    Energy_VC_3_Sim = 0\n",
    "    Energy_Rotary_Air_Lock_Sim = 0\n",
    "    Total_Energy_Sim = 0\n",
    "    reached = 0   \n",
    "    Total_Reward_1 = 0\n",
    "    Total_Reward_2 = 0\n",
    "    Total_Reward_3 = 0\n",
    "    Total_Reward_4 = 0\n",
    "    Total_Reward_5 = 0\n",
    "    Total_Reward_6 = 0\n",
    "    reward_1 = 0\n",
    "    reward_2 = 0\n",
    "    reward_3 = 0\n",
    "    Demand = 0\n",
    "    Energy_Episode = 0\n",
    "    sum_of_actor_loss_1 = 0\n",
    "    sum_of_critic_loss_1 = 0\n",
    "    sum_of_actor_loss_2 = 0\n",
    "    sum_of_critic_loss_2 = 0\n",
    "    sum_of_actor_loss_3 = 0\n",
    "    sum_of_critic_loss_3 = 0\n",
    "    sum_of_actor_loss_4 = 0\n",
    "    sum_of_critic_loss_4 = 0\n",
    "    sum_of_actor_loss_5 = 0\n",
    "    sum_of_critic_loss_5 = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "############################################# ENVIRONMENT ##############################################\n",
    "########################################################################################################\n",
    "\n",
    "##### The below lines of code are for the NN to realize the working ranges of various variables #####\n",
    "def learning_action_range():\n",
    "    \n",
    "    global Conveyor_Motor_Speed, Vibration_Belt_Start, VP_2, VP_Time_2, VP_3, VP_Time_3, Dosing_Speed, Demand\n",
    "    global reward_1, reward_2, reward_3\n",
    "    \n",
    "    if Conveyor_Motor_Speed >  1850 or Conveyor_Motor_Speed < 450:\n",
    "        reward_1 = -30  \n",
    "        reward_2 = -30 \n",
    "        reward_3 = -30\n",
    "    elif Vibration_Belt_Start != 0 or Vibration_Belt_Start != 1:\n",
    "        reward_1 = -30  \n",
    "        reward_2 = -30  \n",
    "        reward_3 = -30\n",
    "    elif VP_Time_2 > 10 or VP_Time_2 < 0:\n",
    "        reward_1 = -30  \n",
    "        reward_2 = -30  \n",
    "        reward_3 = -30\n",
    "    elif VP_Time_3 > 10 or VP_Time_3 < 0:\n",
    "        reward_1 = -30 \n",
    "        reward_2 = -30 \n",
    "        reward_3 = -30\n",
    "    elif Dosing_Speed > 1500 or Dosing_Speed < 450:\n",
    "        reward_1 = -30  \n",
    "        reward_2 = -30 \n",
    "        reward_3 = -30\n",
    "    elif Demand > 100:\n",
    "        reward_1 = -30 \n",
    "        reward_2 = -30 \n",
    "        reward_3 = -30\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "######################################### BULK GOOD SYSTEM #####################################\n",
    "\n",
    "def environment_bgs():\n",
    "    \n",
    "    global Silo_Filllevel_1, Silo_Filllevel_2, Silo_Filllevel_3, Hopper_Filllevel_1, Hopper_Filllevel_2, Hopper_Filllevel_3\n",
    "    global MF_VC_2, MF_VC_3,Demand, Total_Energy_Sim_Prev, Exchanged_Mass_Sim_Prev\n",
    "    global Energy_Conveyor_Sim, Energy_VC_2_Sim, Energy_Vibration_Belt_Sim, Energy_VC_3_Sim, Energy_Rotary_Air_Lock_Sim\n",
    "    global VP_2, VP_3, VP_Time_2, VP_Time_3, MF_S_H_1, MF_S_H_2, MF_S_H_3\n",
    "    global Silo_Empty_1, Hopper_Empty_1, Q_Flip_2, Q_Flip_3, Q_Flip_Prev_2, Q_Flip_Prev_3, Saturator_2, Saturator_3\n",
    "    global VP_Prev_2, VP_Prev_3, Exchanged_Mass_Sim, reward_1, reward_2, reward_3, reward_4, reward_5, reward_6,  reached\n",
    "    global Total_Reward_1, Total_Reward_2, Total_Reward_3, Total_Reward_4, Total_Reward_5, Total_Reward_6, Demand\n",
    "    \n",
    "    bigloop = 0\n",
    "    t = 0\n",
    "    while bigloop <=100:  # 10 secs\n",
    "\n",
    "        ##################### Station 1 #####################\n",
    "\n",
    "        #### Substation 1 - Conveyor Belt - RPM to Mass flow ####\n",
    "\n",
    "\n",
    "        # Massflow Silo to Hopper\n",
    "\n",
    "        # Silo Empty\n",
    "        #Silo_Filllevel_1 = uniform(0,11.42)\n",
    "        #### SILO_STATE ######\n",
    "        if Silo_Filllevel_1 >= 1:\n",
    "            Silo_Empty_1 = 1\n",
    "        else:\n",
    "            Silo_Empty_1 = 0\n",
    "        \n",
    "        ######################\n",
    "\n",
    "        MF_S_H_1 = Conveyor_Motor_Speed * 0.01 / 60 * Silo_Empty_1\n",
    "\n",
    "        cms = Conveyor_Motor_Speed\n",
    "\n",
    "        # Energy - Conveyor Belt\n",
    "\n",
    "        f_cms = lambda x: Conveyor_Motor_Speed*(-81.0493 + 0.5558316*cms - 0.0008993839*cms**2 + 6.578498e-7*cms**3 - 2.197611e-10*cms**4 + 2.721772e-14*cms**5)/(60*1000)\n",
    "        energy,err = integrate.quad(f_cms,t,t+0.1)\n",
    "\n",
    "        Energy_Conveyor_Sim = Energy_Conveyor_Sim +  energy\n",
    "\n",
    "        #### Substation 2 - Silo ####\n",
    "\n",
    "        # Silo Fill level\n",
    "\n",
    "        f_sfl_1 = lambda x: MF_S_H_1 * (-1)\n",
    "        fill,err = integrate.quad(f_sfl_1,t,t+0.1)\n",
    "\n",
    "        #torch.save(Silo_Fill_1_Error, 'Silo_Fill_1_Error.pt')\n",
    "\n",
    "        Silo_Filllevel_1 = Silo_Filllevel_1 + fill\n",
    "        #Mass_Silo_1 = Mass_Silo_1 + fill\n",
    "        \n",
    "        #Silo_Fill_1_Error.append(Silo_Filllevel_1)\n",
    "\n",
    "        if Silo_Filllevel_1 >= 17.42:\n",
    "            Silo_Filllevel_1 = 17.42\n",
    "        elif Silo_Filllevel_1 <= 0:\n",
    "            Silo_Filllevel_1 = 0\n",
    "\n",
    "        # Silo Empty\n",
    "\n",
    "        if Silo_Filllevel_1 >= 1:\n",
    "            Silo_Empty_1 = 1\n",
    "        else:\n",
    "            Silo_Empty_1 = 0\n",
    "\n",
    "        #### Substation 3 - Hopper ####\n",
    "\n",
    "        # Hopper Fill level\n",
    "        f_hfl_1 = lambda x: (MF_S_H_1 - MF_VC_2)\n",
    "\n",
    "        fill, err = integrate.quad(f_hfl_1, t, t+0.1)\n",
    "        Hopper_Filllevel_1 = Hopper_Filllevel_1 + fill\n",
    "\n",
    "        if Hopper_Filllevel_1 >= 9.4:\n",
    "            Hopper_Filllevel_1 = 9.4\n",
    "        elif Hopper_Filllevel_1 <= 0:\n",
    "            Hopper_Filllevel_1 = 0\n",
    "\n",
    "        # Hopper Empty\n",
    "\n",
    "        if Hopper_Filllevel_1 >= 1:\n",
    "            Hopper_Empty_1 = 1\n",
    "        else:\n",
    "            Hopper_Empty_1 = 0\n",
    "\n",
    "        ##################### Station 2 ##################### \n",
    "\n",
    "        #### Substation 1 - Vacuum Pump ####\n",
    "\n",
    "        # Massflow - Previous Hopper to Silo\n",
    "\n",
    "        if t >= VP_Time_2:\n",
    "            VP_2 = 0\n",
    "        else:\n",
    "            VP_2 = 1\n",
    "        \n",
    "        if VP_2 - VP_Prev_2 > 0:              # To know if the quantity of material is rising or falling in the VP\n",
    "            Rising_2 = 1\n",
    "            Falling_2 = 0     \n",
    "        elif VP_2 - VP_Prev_2 <0:             #\n",
    "            Rising_2 = 0 \n",
    "            Falling_2 = 1     #\n",
    "        else:                                  #\n",
    "            Rising_2 = 0 \n",
    "            Falling_2 = 0     #\n",
    "\n",
    "        VP_Prev_2 = VP_2\n",
    "\n",
    "        if Rising_2 == 0 and Falling_2 == 0:    # SR Flip-Flop equivalent\n",
    "            Q_Flip_2 = Q_Flip_Prev_2\n",
    "        elif Rising_2 == 0 and Falling_2 == 1:\n",
    "            Q_Flip_2 = 1\n",
    "        elif Rising_2 == 1 and Falling_2 == 0:\n",
    "            Q_Flip_2 = 0\n",
    "        elif Rising_2 == 1 and Falling_2 == 1:\n",
    "            Q_Flip_2 = 0\n",
    "\n",
    "        Q_Flip_Prev_2 = Q_Flip_2\n",
    "\n",
    "        if Q_Flip_2 == 0:\n",
    "            MF_VC_2 = 0\n",
    "        elif Q_Flip_2 == 0:\n",
    "            Saturator_2 = t - 0.567\n",
    "\n",
    "        if Saturator_2 >= 4.575:\n",
    "            Saturator_2 = 4.575\n",
    "        elif Saturator_2 <= 0:\n",
    "            Saturator_2 = 0\n",
    "\n",
    "\n",
    "        MF_VC_2 = ((0.0664 * Saturator_2) + 0.464) * (Hopper_Empty_1)\n",
    "\n",
    "        # Energy - Vacuum Pump\n",
    "\n",
    "        f_vp_2 = lambda x: (VP_2 * 0.305)\n",
    "\n",
    "        energy,err = integrate.quad(f_vp_2, t, t+0.1)\n",
    "\n",
    "        Energy_VC_2_Sim = Energy_VC_2_Sim + energy\n",
    "\n",
    "        #### Substation 2- Vibration Belt ####\n",
    "\n",
    "        # Massflow Silo to Hopper\n",
    "\n",
    "        # Silo Empty\n",
    "\n",
    "        if Silo_Filllevel_2 >= 1:\n",
    "            Silo_Empty_2 = 1\n",
    "        else:\n",
    "            Silo_Empty_2 = 0\n",
    "\n",
    "        MF_S_H_2 = Vibration_Belt_Start * 0.4 * Silo_Empty_2\n",
    "\n",
    "        # Energy Vibration Belt\n",
    "\n",
    "        f_env = lambda x: (26.9 * Vibration_Belt_Start / 1000)\n",
    "        energy, err = integrate.quad(f_env,t,t+0.1)\n",
    "\n",
    "        Energy_Vibration_Belt_Sim = Energy_Vibration_Belt_Sim + energy\n",
    "\n",
    "        #### Substation 3 - Silo ####\n",
    "\n",
    "        # Silo Fill level\n",
    "\n",
    "        f_sfl_2 = lambda x: (MF_VC_2 - MF_S_H_2)\n",
    "        fill,err = integrate.quad(f_sfl_2,t,t+0.1)\n",
    "\n",
    "        Silo_Filllevel_2  = Silo_Filllevel_2 + fill\n",
    "        #Mass_Silo_2 = Mass_Silo_2 + fill\n",
    "\n",
    "        if Silo_Filllevel_2 >= 17.42:\n",
    "            Silo_Filllevel_2 = 17.42\n",
    "        elif Silo_Filllevel_2 <= 0:\n",
    "            Silo_Filllevel_2 = 0\n",
    "\n",
    "\n",
    "        # Silo Empty\n",
    "\n",
    "        if Silo_Filllevel_2 >= 1:\n",
    "            Silo_Empty_2 = 1\n",
    "        else:\n",
    "            Silo_Empty_2 = 0\n",
    "\n",
    "        #### Substation 3 - Hopper ####\n",
    "\n",
    "        # Hopper Fill level\n",
    "\n",
    "        f_hfl_2 = lambda x: (MF_S_H_2 - MF_VC_3)\n",
    "\n",
    "        fill,err = integrate.quad(f_hfl_2,t,t+0.1)\n",
    "\n",
    "        Hopper_Filllevel_2 = Hopper_Filllevel_2 + fill\n",
    "\n",
    "        if Hopper_Filllevel_2 >= 9.4:\n",
    "            Hopper_Filllevel_2 = 9.4\n",
    "        elif Hopper_Filllevel_2 <= 0:\n",
    "            Hopper_Filllevel_2 = 0\n",
    "\n",
    "        # Hopper Empty\n",
    "\n",
    "        if Hopper_Filllevel_2 >= 1:\n",
    "            Hopper_Empty_2 = 1\n",
    "        else:\n",
    "            Hopper_Empty_2 = 0\n",
    "\n",
    "\n",
    "        ##################### Station 3 ##################### \n",
    "\n",
    "        #### Substation 1 - Vacuum Pump ####\n",
    "\n",
    "        if t >= VP_Time_3:\n",
    "            VP_3 = 0\n",
    "        else: \n",
    "            VP_3 = 0\n",
    "\n",
    "        if VP_3 - VP_Prev_3 > 0:              # To know if the quantity of material is rising or falling in the VP\n",
    "            Rising_3 = 1 \n",
    "            Falling_3 = 0      #\n",
    "        elif VP_3 - VP_Prev_2 <0:             #\n",
    "            Rising_3 = 0 \n",
    "            Falling_3 = 1      #\n",
    "        elif VP_3 - VP_Prev_3 == 0:            #\n",
    "            Rising_3 = 0 \n",
    "            Falling_3 = 0      #\n",
    "\n",
    "        VP_Prev_3 = VP_3\n",
    "\n",
    "        if Rising_3 == 0 and Falling_3 == 0:    # SR Flip-Flop equivalent\n",
    "            Q_Flip_3 = Q_Flip_Prev_3\n",
    "        elif Rising_3 == 0 and Falling_3 == 1:\n",
    "            Q_Flip_3 = 1\n",
    "        elif Rising_3 == 1 and Falling_3 == 0:\n",
    "            Q_Flip_3 = 0\n",
    "        elif Rising_3 == 1 and Falling_3 == 1:\n",
    "            Q_Flip_3 = 0\n",
    "\n",
    "        Q_Flip_Prev_3 = Q_Flip_3\n",
    "\n",
    "        if Q_Flip_3 == 0:\n",
    "            MF_VC_3 = 0\n",
    "        elif Q_Flip_3 == 0:\n",
    "            Saturator_3 = t - 0.979\n",
    "\n",
    "        if Saturator_3 >= 9.5:\n",
    "            Saturator_3 = 9.5\n",
    "        elif Saturator_3 <= 0:\n",
    "            Saturator_3 = 0\n",
    "\n",
    "\n",
    "\n",
    "        MF_VC_3 = ((0.0192 * Saturator_3) + 0.3535) * (Hopper_Empty_2)\n",
    "\n",
    "        # Energy - Vacuum Pump\n",
    "\n",
    "        f_vp_3 = lambda x: (VP_3 * 0.456)\n",
    "\n",
    "        energy,err = integrate.quad(f_vp_3,t,t+0.1)\n",
    "\n",
    "        Energy_VC_3_Sim = Energy_VC_3_Sim + energy\n",
    "\n",
    "        #### Substation 2 - Rotary Air lock ####\n",
    "\n",
    "        # Massflow Silo to Hopper\n",
    "\n",
    "        # Silo Empty\n",
    "\n",
    "        if Silo_Filllevel_3 >= 1:\n",
    "            Silo_Empty_3 = 1\n",
    "        else:\n",
    "            Silo_Empty_3 = 0\n",
    "\n",
    "        MF_S_H_3 = (Dosing_Speed) * (Silo_Empty_3) * 0.01249 / 60\n",
    "\n",
    "        # Energy Rotary Air Lock\n",
    "\n",
    "        f_eral = lambda x: (Dosing_Speed * 370 / (1500 * 1000))\n",
    "\n",
    "        energy,err = integrate.quad(f_eral,t,t+0.1)\n",
    "\n",
    "        Energy_Rotary_Air_Lock_Sim = Energy_Rotary_Air_Lock_Sim + energy\n",
    "\n",
    "        #### Substation 3 - Silo ####\n",
    "\n",
    "        # Silo Fill level\n",
    "\n",
    "        f_sfl_3 = lambda x: (MF_VC_3 - MF_S_H_3)\n",
    "        fill,err = integrate.quad(f_sfl_3,t,t+0.1)\n",
    "\n",
    "        Silo_Filllevel_3  = Silo_Filllevel_3 + fill\n",
    "        #Mass_Silo_3 = Mass_Silo_3 + fill\n",
    "\n",
    "        if Silo_Filllevel_3 >= 17.45:\n",
    "            Silo_Filllevel_3 = 17.45\n",
    "        elif Silo_Filllevel_3 <= 0:\n",
    "            Silo_Filllevel_3 = 0\n",
    "\n",
    "        # Silo Empty\n",
    "\n",
    "        if Silo_Filllevel_3 >= 1:\n",
    "            Silo_Empty_3 = 1\n",
    "        else:\n",
    "            Silo_Empty_3 = 0\n",
    "\n",
    "        #### Substation 3 - Hopper ####\n",
    "\n",
    "        # Hopper Fill level\n",
    "\n",
    "        f_hfl_3 = lambda x: (MF_S_H_1 - Demand)\n",
    "\n",
    "        fill,err = integrate.quad(f_hfl_3,t,t+0.1)\n",
    "        \n",
    "        Hopper_Filllevel_3 = Hopper_Filllevel_3 + fill\n",
    "\n",
    "        if Hopper_Filllevel_3 >= 9.4:\n",
    "            Hopper_Filllevel_3 = 9.4\n",
    "        elif Hopper_Filllevel_3 <= 0:\n",
    "            Hopper_Filllevel_3 = 0\n",
    "    \n",
    "        f_demand = lambda x: Demand                      # Overall Mass transported by the system\n",
    "        dem,err = integrate.quad(f_demand,t,t+0.1)       #\n",
    "        Exchanged_Mass_Sim = Exchanged_Mass_Sim + dem    #\n",
    "\n",
    "        # Hopper Empty\n",
    "\n",
    "        if Hopper_Filllevel_3 >= 1:\n",
    "            Hopper_Empty_3 = 1\n",
    "        else:\n",
    "            Hopper_Empty_3 = 0\n",
    "        ##########################################################\n",
    "\n",
    "        t = t + 0.1                             # Next time step \n",
    "\n",
    "        bigloop = bigloop + 1\n",
    "        ################################################################################################################   \n",
    "    Total_Energy_Sim = sum([Energy_Conveyor_Sim, Energy_VC_2_Sim, Energy_Vibration_Belt_Sim, Energy_VC_3_Sim, Energy_Rotary_Air_Lock_Sim])\n",
    "\n",
    "    ############ Rewards ###########    \n",
    "\n",
    "    #### Terminal State ####\n",
    "    if Exchanged_Mass_Sim >= 150000:\n",
    "        reward_1 = (1000000 - Energy_Conveyor_Sim)/100\n",
    "        reward_2 = (1000000 - Energy_VC_2_Sim)/100\n",
    "        reward_3 = (1000000 - Energy_Vibration_Belt_Sim)/100\n",
    "        reward_4 = (1000000 - Energy_VC_3_Sim)/100\n",
    "        reward_5 = (1000000 - Energy_Rotary_Air_Lock_Sim)/100\n",
    "        reward_6 = (1200000 - Energy_VC_2_Sim - Energy_VC_3_Sim)/100\n",
    "        \n",
    "        reached = 1\n",
    "\n",
    "    else:\n",
    "        reward_1 = -1\n",
    "        reward_2 = -1\n",
    "        reward_3 = -1\n",
    "        reward_4 = -1\n",
    "        reward_5 = -1\n",
    "        reward_6 = -1\n",
    "        reached = 0\n",
    "    \n",
    "    #if steps_in_episode == 2:\n",
    "     #   Total_Energy_Sim_Prev = Total_Energy_Sim/steps_in_episode\n",
    "      #  Exchanged_Mass_Sim_Prev = Exchanged_Mass_Sim\n",
    "        \n",
    "    if steps_in_episode%30 == 0:\n",
    "        if steps_in_episode != 0:\n",
    "            if Total_Energy_Sim/steps_in_episode > Total_Energy_Sim_Prev:\n",
    "                reward_1 = reward_1 - Energy_Conveyor_Sim/steps_in_episode\n",
    "                reward_2 = reward_2 - Energy_VC_2_Sim/steps_in_episode\n",
    "                reward_3 = reward_3 - Energy_Vibration_Belt_Sim/steps_in_episode\n",
    "                reward_4 = reward_4 - Energy_VC_3_Sim/steps_in_episode\n",
    "                reward_5 = reward_5 - Energy_Rotary_Air_Lock_Sim/steps_in_episode\n",
    "                reward_6 = reward_6 - (Energy_VC_2_Sim - Energy_VC_3_Sim)/steps_in_episode\n",
    "                Total_Energy_Sim_Prev = Total_Energy_Sim/steps_in_episode\n",
    "                \n",
    "    if steps_in_episode%30 == 0:\n",
    "        if steps_in_episode != 0:\n",
    "            if Exchanged_Mass_Sim/steps_in_episode > Exchanged_Mass_Sim_Prev:\n",
    "                reward_1 = reward_1 - Exchanged_Mass_Sim_Prev/steps_in_episode\n",
    "                reward_2 = reward_2 - Exchanged_Mass_Sim_Prev/steps_in_episode\n",
    "                reward_3 = reward_3 - Exchanged_Mass_Sim_Prev/steps_in_episode\n",
    "                reward_4 = reward_4 - Exchanged_Mass_Sim_Prev/steps_in_episode\n",
    "                reward_5 = reward_5 - Exchanged_Mass_Sim_Prev/steps_in_episode\n",
    "                reward_6 = reward_6 - Exchanged_Mass_Sim_Prev/steps_in_episode\n",
    "                Exchanged_Mass_Sim_Prev = Exchanged_Mass_Sim/steps_in_episode\n",
    "\n",
    "    if steps_in_episode >= 488:\n",
    "        reward_1 = -40\n",
    "        reward_2 = -40\n",
    "        reward_3 = -40\n",
    "        reward_4 = -40\n",
    "        reward_5 = -40\n",
    "        reward_6 = -40\n",
    "    \n",
    "    Total_Reward_1 = Total_Reward_1 + reward_1\n",
    "    Total_Reward_2 = Total_Reward_2 + reward_2\n",
    "    Total_Reward_3 = Total_Reward_3 + reward_3\n",
    "    Total_Reward_4 = Total_Reward_4 + reward_4\n",
    "    Total_Reward_5 = Total_Reward_5 + reward_5\n",
    "    Total_Reward_6 = Total_Reward_6 + reward_6\n",
    "    \n",
    "    return Silo_Filllevel_1, Silo_Filllevel_2, Silo_Filllevel_3, Hopper_Filllevel_1, Hopper_Filllevel_2, Hopper_Filllevel_3, Energy_Conveyor_Sim, Energy_VC_2_Sim, Energy_Vibration_Belt_Sim, Energy_VC_3_Sim, Energy_Rotary_Air_Lock_Sim, Total_Energy_Sim, VP_2, VP_3, VP_Time_2, VP_Time_3, MF_VC_2, MF_VC_3, MF_S_H_1, MF_S_H_2, MF_S_H_3, Silo_Empty_1, Hopper_Empty_1, Q_Flip_2, Q_Flip_3, Q_Flip_Prev_2, Q_Flip_Prev_3, Saturator_2, Saturator_3, VP_Prev_2, VP_Prev_3, Exchanged_Mass_Sim, reached, reward_1, reward_2, reward_3, Total_Reward_1, Total_Reward_2, Total_Reward_3, Demand, Total_Energy_Sim \n",
    "\n",
    "# 0 Silo_Filllevel_1      # 7 Energy_VC_2_Sim              #14 VP_Time_2    #21 Silo_Empty_1      #28 Saturator_3          #35 reward_3\n",
    "# 1 Silo_Filllevel_2      # 8 Energy_Vibration_Belt_Sim    #15 VP_Time_3    #22 Hopper_Empty_1    #29 VP_Prev_2            #36 Total_Reward_1\n",
    "# 2 Silo_Filllevel_3      # 9 Energy_VC_3_Sim              #16 MF_VC_2      #23 Q_Flip_2          #30 VP_Prev_3            #37 Total_Reward_2\n",
    "# 3 Hopper_Filllevel_1    #10 Energy_Rotary_Air_Lock_Sim   #17 MF_VC_3      #24 Q_Flip_3          #31 Exchanged_Mass_Sim   #38 Total_Reward_1\n",
    "# 4 Hopper_Filllevel_2    #11 Total_Energy_Sim             #18 MF_S_H_1     #25 Q_Flip_Prev_2     #32 reached              #39 Demand\n",
    "# 5 Hopper_Filllevel_3    #12 VP_2                         #19 MF_S_H_2     #26 Q_Flip_Prev_3     #33 reward_1             #40 Total_Energy_Sim\n",
    "# 6 Energy_Conveyor_Sim   #13 VP_3                         #20 MF_S_H_3     #27 Saturator_2       #34 reward_2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############ Main #############\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "print\n",
    "print(\"Simulation Started at:\")\n",
    "print(str(now))\n",
    "#import train\n",
    "#import buffer\n",
    "\n",
    "MAX_EPISODES = 2500  # Madhav kept it as 2500 states for best result\n",
    "MAX_STEPS = 550\n",
    "MAX_BUFFER = 100000\n",
    "\n",
    "Energy_Consumed_Per_Episode = []\n",
    "Episode_counter = []\n",
    "Terminal_reached = []\n",
    "Reward_Per_Episode_1 = []\n",
    "Reward_Per_Episode_2 = []\n",
    "Reward_Per_Episode_3 = []\n",
    "Reward_Per_Episode_4 = []\n",
    "Reward_Per_Episode_5 = []\n",
    "Reward_Per_Episode_6 = []\n",
    "Actor_loss_per_episode_1 = []\n",
    "Critic_loss_per_episode_1 = []\n",
    "Actor_loss_per_episode_2 = []\n",
    "Critic_loss_per_episode_2 = []\n",
    "Actor_loss_per_episode_3 = []\n",
    "Critic_loss_per_episode_3 = []\n",
    "Actor_loss_per_episode_4 = []\n",
    "Critic_loss_per_episode_4 = []\n",
    "Actor_loss_per_episode_5 = []\n",
    "Critic_loss_per_episode_5 = []\n",
    "\n",
    "\n",
    "#MAX_TOTAL_REWARD = 300\n",
    "#S_DIM = env.observation_space.shape[0]\n",
    "#A_DIM = env.action_space.shape[0]\n",
    "#A_MAX = env.action_space.high[0]\n",
    "\n",
    "#print (' State Dimensions :- ', S_DIM)\n",
    "#print (' Action Dimensions :- ', A_DIM)\n",
    "#print (' Action Max :- ', A_MAX)\n",
    "\n",
    "ram_1 = MemoryBuffer(MAX_BUFFER)\n",
    "ram_2 = MemoryBuffer(MAX_BUFFER)\n",
    "ram_3 = MemoryBuffer(MAX_BUFFER)\n",
    "ram_4 = MemoryBuffer(MAX_BUFFER)\n",
    "ram_5 = MemoryBuffer(MAX_BUFFER)\n",
    "ram_6 = MemoryBuffer(MAX_BUFFER)\n",
    "\n",
    "trainer_1 = Trainer(5, 1, ram_1)\n",
    "trainer_2 = Trainer(5, 1, ram_2) # , A_MAX\n",
    "trainer_3 = Trainer(5, 1, ram_3) # , A_MAX\n",
    "trainer_4 = Trainer(5, 1, ram_4) # , A_MAX\n",
    "trainer_5 = Trainer(5, 1, ram_5) # , A_MAX\n",
    "trainer_6 = Trainer(5, 1, ram_6) # , A_MAX\n",
    "\n",
    "for _ep in range(MAX_EPISODES):\n",
    "    state_space_reset()\n",
    "    initial_state()\n",
    "    Demand = uniform(10,50)\n",
    "    \n",
    "    for steps_in_episode in range(MAX_STEPS):\n",
    "        #env.render()\n",
    "        \n",
    "        state_1 = [Silo_Filllevel_1/17.42, Hopper_Filllevel_1/9.1, MF_VC_2, ((Demand-10)/40), ((Demand-10)/40)]\n",
    "        state_2 = [Silo_Filllevel_2/17.42, Hopper_Filllevel_2/9.1, MF_VC_2, MF_VC_3, ((Demand-10)/40)]\n",
    "        state_3 = [Silo_Filllevel_3/17.42, Hopper_Filllevel_3/9.1, MF_VC_2, MF_VC_3, ((Demand-10)/40)]\n",
    "        state_space_1 = torch.tensor(state_1).float()\n",
    "        state_space_2 = torch.tensor(state_2).float()\n",
    "        state_space_3 = torch.tensor(state_3).float()\n",
    "        \n",
    "        if _ep <2000:\n",
    "            prob = (-0.0445)*_ep + 90\n",
    "        else:\n",
    "            prob = 1\n",
    "                \n",
    "        randomizer = randrange(0, 101)\n",
    "        if randomizer < prob:\n",
    "            Conveyor_Motor_Speed = ((trainer_1.get_exploration_action(state_space_1)) * 1400) + 450\n",
    "            #print('Conveyor_Motor_Speed', Conveyor_Motor_Speed)\n",
    "            \n",
    "            VP__Time_2 = (trainer_2.get_exploration_action(state_space_2)) * 10\n",
    "            #print('VP__Time_2',VP__Time_2)\n",
    "            \n",
    "            Vibration_Belt_Start = trainer_3.get_exploration_action(state_space_2)\n",
    "            if Vibration_Belt_Start < 0.5:\n",
    "                Vibration_Belt_Start = 0\n",
    "            else: Vibration_Belt_Start = 1\n",
    "            #print('Vibration_Belt_Start',Vibration_Belt_Start)\n",
    "            \n",
    "            VP_Time_3 = (trainer_4.get_exploration_action(state_space_3)) * 10\n",
    "            #print('VP_Time_3',VP_Time_3)\n",
    "            \n",
    "            Dosing_Speed = ((trainer_5.get_exploration_action(state_space_3)) * 1050) + 450\n",
    "            #print('Dosing_Speed',Dosing_Speed)\n",
    "            \n",
    "            Demand = ((trainer_6.get_exploration_action(state_space_3)) * 40) + 10\n",
    "            #print('Demand', Demand)\n",
    "            #print('\\nExplore \\n')\n",
    "            \n",
    "        else:\n",
    "            Conveyor_Motor_Speed = ((trainer_1.get_exploitation_action(state_space_1)) * 1400) + 450\n",
    "            #print('Conveyor_Motor_Speed', Conveyor_Motor_Speed)\n",
    "            \n",
    "            VP__Time_2 = (trainer_2.get_exploitation_action(state_space_2)) * 10\n",
    "            #print('VP__Time_2',VP__Time_2)\n",
    "            \n",
    "            Vibration_Belt_Start = trainer_3.get_exploitation_action(state_space_2)\n",
    "            if Vibration_Belt_Start < 0.5:\n",
    "                Vibration_Belt_Start = 0\n",
    "            else: Vibration_Belt_Start = 1\n",
    "            #print('Vibration_Belt_Start',Vibration_Belt_Start)\n",
    "            \n",
    "            VP_Time_3 = (trainer_4.get_exploitation_action(state_space_3)) * 10\n",
    "            #print('VP_Time_3',VP_Time_3)\n",
    "            \n",
    "            Dosing_Speed = ((trainer_5.get_exploitation_action(state_space_3)) * 1050) + 450\n",
    "            #print('Dosing_Speed',Dosing_Speed)\n",
    "            \n",
    "            Demand = ((trainer_6.get_exploitation_action(state_space_3)) * 40) + 10\n",
    "            #print('Demand', Demand)\n",
    "            #print('\\nExploit \\n')\n",
    "            #print(Conveyor_Motor_Speed, VP_Time_2, VP_Time_3, Dosing_Speed, Vibration_Belt_Start)\n",
    "            \n",
    "        #action_1 = trainer_1.get_exploration_action(state)\n",
    "        # if _ep%5 == 0:\n",
    "        # \t# validate every 5th episode\n",
    "        # \taction = trainer.get_exploitation_action(state)\n",
    "        # else:\n",
    "        # \t# get action based on observation, use exploration policy here\n",
    "        # \taction = trainer.get_exploration_action(state)\n",
    "        #new_observation, reward, done, info = env.step(action)\n",
    "\n",
    "        new_state = environment_bgs()\n",
    "        new_Silo_Filllevel_1 = new_state[0]\n",
    "        new_Silo_Filllevel_2 = new_state[1]\n",
    "        new_Silo_Filllevel_3 = new_state[2]\n",
    "        new_Hopper_Filllevel_1 = new_state[3]\n",
    "        new_Hopper_Filllevel_2 = new_state[4]\n",
    "        new_Hopper_Filllevel_3 = new_state[5]\n",
    "        new_MF_VC_2 = new_state[16]\n",
    "        new_MF_VC_3 = new_state[17]\n",
    "        new_Demand = Demand\n",
    "        Total_Energy_Sim = new_state[40]\n",
    "            \n",
    "        #print('hi')\n",
    "            \n",
    "        new_state_1 = [new_Silo_Filllevel_1, new_Hopper_Filllevel_1, new_MF_VC_2, new_Demand, 0]\n",
    "        new_state_2 = [new_Silo_Filllevel_2, new_Hopper_Filllevel_2, new_MF_VC_2, new_MF_VC_3, new_Demand]\n",
    "        new_state_3 = [new_Silo_Filllevel_3, new_Hopper_Filllevel_3, new_MF_VC_2, new_MF_VC_3, new_Demand]\n",
    "        new_state_space_1 = torch.tensor(new_state_1)\n",
    "        new_state_space_2 = torch.tensor(new_state_2)\n",
    "        new_state_space_3 = torch.tensor(new_state_3)\n",
    "        \n",
    "            # push this exp in ram\n",
    "        ram_1.add(state_space_1.tolist(), ((Conveyor_Motor_Speed - 450)/(1400)), reward_1/100, new_state_space_1.tolist())\n",
    "        ram_2.add(state_space_2.tolist(), [VP_Time_2/10], reward_2/100, new_state_space_2.tolist())\n",
    "        ram_3.add(state_space_2.tolist(), [Vibration_Belt_Start], reward_3/100, new_state_space_2.tolist())\n",
    "        ram_4.add(state_space_3.tolist(), VP_Time_3/10, reward_4/100, new_state_space_3.tolist())\n",
    "        ram_5.add(state_space_3.tolist(), ((Dosing_Speed - 450)/(1050)), reward_5/100, new_state_space_3.tolist())\n",
    "        ram_6.add(state_space_3.tolist(), ((Dosing_Speed - 450)/(1050)), reward_5/100, new_state_space_3.tolist())\n",
    "        \n",
    "        #print(' \\n Action counter', r)\n",
    "        \n",
    "            # perform optimization\n",
    "        trainer_1.optimize()\n",
    "        trainer_2.optimize()        \n",
    "        trainer_3.optimize()\n",
    "        trainer_4.optimize()\n",
    "        trainer_5.optimize()\n",
    "        \n",
    "        #C = trainer_1.A\n",
    "        #D = trainer_1.B\n",
    "        #E = trainer_2.A\n",
    "        #F = trainer_2.B\n",
    "        #G = trainer_3.A\n",
    "        #H = trainer_3.B\n",
    "        #I = trainer_4.A\n",
    "        #J = trainer_4.B\n",
    "        #K = trainer_5.A\n",
    "        #L = trainer_5.B\n",
    "        \n",
    "        #sum_of_actor_loss_1 = sum_of_actor_loss + C\n",
    "        #sum_of_critic_loss_1 = sum_of_critic_loss + D\n",
    "        #sum_of_actor_loss_2 = sum_of_actor_loss + E\n",
    "        #sum_of_critic_loss_2 = sum_of_critic_loss +  F\n",
    "        #sum_of_actor_loss_3 = sum_of_actor_loss + G \n",
    "        #sum_of_critic_loss_3 = sum_of_critic_loss + H \n",
    "        #sum_of_actor_loss_4 = sum_of_actor_loss + I\n",
    "        #sum_of_critic_loss_4 = sum_of_critic_loss + J \n",
    "        #sum_of_actor_loss_5 = sum_of_actor_loss + K\n",
    "        #sum_of_critic_loss_5 = sum_of_critic_loss + L \n",
    "        \n",
    "        if reached == 1:\n",
    "            break\n",
    "        \n",
    "############################### End of Episode ###################################\n",
    "        \n",
    "    Energy_Consumed_Per_Episode.append(Total_Energy_Sim)\n",
    "    Episode_counter.append(steps_in_episode)\n",
    "    Terminal_reached.append(reached)\n",
    "    \n",
    "    Reward_Per_Episode_1.append(Total_Reward_1)\n",
    "    Reward_Per_Episode_2.append(Total_Reward_2)\n",
    "    Reward_Per_Episode_3.append(Total_Reward_3)\n",
    "    Reward_Per_Episode_4.append(Total_Reward_4)\n",
    "    Reward_Per_Episode_5.append(Total_Reward_5)\n",
    "    Reward_Per_Episode_6.append(Total_Reward_6)\n",
    "    \n",
    "    #Actor_loss_per_episode_1.append(sum_of_actor_loss_1)\n",
    "    #Critic_loss_per_episode_1.append(sum_of_critic_loss_1)\n",
    "    #Actor_loss_per_episode_2.append(sum_of_actor_loss_2)\n",
    "    #Critic_loss_per_episode_2.append(sum_of_critic_loss_2)\n",
    "    #Actor_loss_per_episode_3.append(sum_of_actor_loss_3)\n",
    "    #Critic_loss_per_episode_3.append(sum_of_critic_loss_3)\n",
    "    #Actor_loss_per_episode_4.append(sum_of_actor_loss_4)\n",
    "    #Critic_loss_per_episode_4.append(sum_of_critic_loss_4)\n",
    "    #Actor_loss_per_episode_5.append(sum_of_actor_loss_5)\n",
    "    #Critic_loss_per_episode_5.append(sum_of_critic_loss_5)\n",
    "    \n",
    "    # check memory consumption and clear memory\n",
    "    gc.collect()\n",
    "    #print('Episode: ', _ep)\n",
    "    # process = psutil.Process(os.getpid())\n",
    "    # print(process.memory_info().rss)\n",
    "    torch.save(Energy_Consumed_Per_Episode, 'Energy_Consumed_Per_Episode.pt')\n",
    "    torch.save(Terminal_reached, 'Terminal_reached.pt')\n",
    "    torch.save(Reward_Per_Episode_1, 'Reward_Per_Episode_1.pt')\n",
    "    torch.save(Reward_Per_Episode_2, 'Reward_Per_Episode_2.pt')\n",
    "    torch.save(Reward_Per_Episode_3, 'Reward_Per_Episode_3.pt')\n",
    "    torch.save(Reward_Per_Episode_4, 'Reward_Per_Episode_4.pt')\n",
    "    torch.save(Reward_Per_Episode_5, 'Reward_Per_Episode_5.pt')\n",
    "    torch.save(Reward_Per_Episode_6, 'Reward_Per_Episode_6.pt')\n",
    "    torch.save(Episode_counter, 'Episode_counter.pt')\n",
    "    \n",
    "    #torch.save(Actor_loss_per_episode_1, 'Actor_loss_per_episode_1')\n",
    "    #torch.save(Critic_loss_per_episode_1, 'Critic_loss_per_episode_1')\n",
    "    #torch.save(Actor_loss_per_episode_2, 'Actor_loss_per_episode_2')\n",
    "    #torch.save(Critic_loss_per_episode_2, 'Critic_loss_per_episode_2')\n",
    "    #torch.save(Actor_loss_per_episode_3, 'Actor_loss_per_episode_3')\n",
    "    #torch.save(Critic_loss_per_episode_3, 'Critic_loss_per_episode_3')\n",
    "    #torch.save(Actor_loss_per_episode_4, 'Actor_loss_per_episode_4')\n",
    "    #torch.save(Critic_loss_per_episode_4, 'Critic_loss_per_episode_4')\n",
    "    #torch.save(Actor_loss_per_episode_5, 'Actor_loss_per_episode_5')\n",
    "    #torch.save(Critic_loss_per_episode_5, 'Critic_loss_per_episode_5')\n",
    "    \n",
    "    \n",
    "    if _ep%40 == 0:        \n",
    "        print(_ep)\n",
    "        trainer_1.save_models(_ep, r\"/home/at-lab/ownCloud/bulk_good (1)/Madhav/Non linear exploration/target_actor_param_1.pt\",r\"/home/at-lab/ownCloud/bulk_good (1)/Madhav/Non linear exploration/target_critic_param_1.pt\")\n",
    "        trainer_2.save_models(_ep, r\"/home/at-lab/ownCloud/bulk_good (1)/Madhav/Non linear exploration/target_actor_param_2.pt\",r\"/home/at-lab/ownCloud/bulk_good (1)/Madhav/Non linear exploration/target_critic_param_2.pt\")\n",
    "        trainer_3.save_models(_ep, r\"/home/at-lab/ownCloud/bulk_good (1)/Madhav/Non linear exploration/target_actor_param_3.pt\",r\"/home/at-lab/ownCloud/bulk_good (1)/Madhav/Non linear exploration/target_critic_param_3.pt\")\n",
    "        trainer_4.save_models(_ep, r\"/home/at-lab/ownCloud/bulk_good (1)/Madhav/Non linear exploration/target_actor_param_4.pt\",r\"/home/at-lab/ownCloud/bulk_good (1)/Madhav/Non linear exploration/target_critic_param_4.pt\")\n",
    "        trainer_5.save_models(_ep, r\"/home/at-lab/ownCloud/bulk_good (1)/Madhav/Non linear exploration/target_actor_param_5.pt\",r\"/home/at-lab/ownCloud/bulk_good (1)/Madhav/Non linear exploration/target_critic_param_5.pt\")\n",
    "        trainer_6.save_models(_ep, r\"/home/at-lab/ownCloud/bulk_good (1)/Madhav/Non linear exploration/target_actor_param_6.pt\",r\"/home/at-lab/ownCloud/bulk_good (1)/Madhav/Non linear exploration/target_critic_param_6.pt\")\n",
    "    # C:\\Users\\hp\\Desktop\\Python DDPG\n",
    "    #torch.save(trainer_1.Actor.state_dict(), 'model_1.pt')\n",
    "    #model_critic = \n",
    "print ('\\n \\nCompleted episodes')\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "print\n",
    "print(\"Simulation Ended at:\")\n",
    "print(str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
